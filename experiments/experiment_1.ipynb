{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:09.158003Z",
     "start_time": "2025-03-27T19:06:07.117089Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import os\n",
    "import utils\n",
    "import optax\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from tueplots import bundles\n",
    "# bundle = bundles.icml2024()\n",
    "plt.rcParams.update(bundles.icml2024(usetex=False, family='sans-serif'))\n",
    "# Hyperparameters\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY=1e-3\n",
    "STEPS = 676\n",
    "PRINT_EVERY = 25\n",
    "SEED = 12345678\n",
    "USE_RESIDUAL = True\n",
    "STRIDE_FIRST_LAYER=2\n",
    "\n",
    "FIGURE_SAVEDIR = 'Experiment_figures/'\n",
    "if not os.path.exists(FIGURE_SAVEDIR):\n",
    "    os.makedirs(FIGURE_SAVEDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d394beaa9793bff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:09.190028Z",
     "start_time": "2025-03-27T19:06:09.185296Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_batch_for_classifier(bs, data_dir, t=-1):\n",
    "\n",
    "    files = os.listdir(data_dir)\n",
    "    # select some random files to load:\n",
    "    selected_files = np.random.choice(files, size=bs, replace=True)  # list of .npz files\n",
    "    data = []\n",
    "    labels = []\n",
    "    for f in selected_files:\n",
    "        # load the final state of each simulation. shape is (t, 2, grid_size, grid_size)\n",
    "        npz = np.load(os.path.join(data_dir, f))\n",
    "        arr = npz['data']\n",
    "        label = npz['label']\n",
    "        if t is not None:\n",
    "            t_int = t\n",
    "            arr = arr[t_int]\n",
    "        data.append(\n",
    "            arr[None, ...]\n",
    "        )  # now shape (1, [t], 2, grid_size, grid_size)\n",
    "        labels.append(np.array([label]))\n",
    "    return np.concatenate(data), np.concatenate(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7cf86258f2935e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:09.445364Z",
     "start_time": "2025-03-27T19:06:09.442563Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_arr, test_label = load_data_batch_for_classifier(1, '../data/MNIST_jaxCPM_data', t=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7a5e75b2dce734",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:16.826167Z",
     "start_time": "2025-03-27T19:06:09.472402Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '../data/MNIST_jaxCPM_data'\n",
    "all_data, all_labels = load_data_batch_for_classifier(len(os.listdir(path)),\n",
    "        path, t=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b74a980cf4565",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:16.866545Z",
     "start_time": "2025-03-27T19:06:16.848852Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data = all_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3df0cd8213f1ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:17.352488Z",
     "start_time": "2025-03-27T19:06:16.896374Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c0f287f76b7f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:17.512197Z",
     "start_time": "2025-03-27T19:06:17.466219Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c73e27809240679",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:18.784455Z",
     "start_time": "2025-03-27T19:06:18.775838Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5bd287953be2fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:19.851078Z",
     "start_time": "2025-03-27T19:06:19.847314Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae77e02a57b2037",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:20.225179Z",
     "start_time": "2025-03-27T19:06:20.220535Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdab50c8a526779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:21.379031Z",
     "start_time": "2025-03-27T19:06:20.710972Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 5)\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    plotted = utils.plot_cell_image(all_data[i], ax)\n",
    "    # ax.set_title(f\"Label: {all_labels[i]}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURE_SAVEDIR+'some_real_cpm_mnist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de48e89ab0dbc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:36.837866Z",
     "start_time": "2025-03-27T19:06:36.556357Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot four example mnist images:\n",
    "colors = [\n",
    "            np.array([[0.,0.,0.]]),# black\n",
    "            np.array([[0.,0.,0.25]]),# dark blue\n",
    "            np.array([[1.,0.,0.]]), #  red\n",
    "            np.array([[204.,255.,11.]]) / 255. #  light green\n",
    "        ]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(4,1),  gridspec_kw={'wspace': 0.05, 'hspace': 0.05})\n",
    "idx_to_plot = [14,5,8,13]\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    idx = idx_to_plot[i]\n",
    "    utils.plot_cell_image(all_data[idx], ax, colors=colors)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\n",
    "    'Cellular\\nMNIST', fontsize=8, labelpad=10, \n",
    "    rotation=90, va=\"center\", ha=\"center\"\n",
    ")\n",
    "        \n",
    "# Add group labels for \"Type A\" and \"Type B\"\n",
    "fig.text(0.325, 0.05, 'Open structures', fontsize=8, ha='center', va='top')\n",
    "fig.text(0.72, 0.05, 'Enclosed structures', fontsize=8, ha='center', va='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURE_SAVEDIR+'real_cellular_mnist.png', dpi=400, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5290bf17e359c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:42.112281Z",
     "start_time": "2025-03-27T19:06:42.108048Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7624df5d05a94387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:42.736388Z",
     "start_time": "2025-03-27T19:06:42.732551Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b2bf22e70786e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:43.109881Z",
     "start_time": "2025-03-27T19:06:43.106657Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a240045918324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:44.539095Z",
     "start_time": "2025-03-27T19:06:44.534822Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into a training, validation and test set\n",
    "train_idx = int(0.8 * len(all_data))\n",
    "val_idx = int(0.9 * len(all_data))\n",
    "test_idx = len(all_data)\n",
    "\n",
    "train_data = all_data[:train_idx, 1:2]  # only take second channel since this is the type channel\n",
    "train_labels = all_labels[:train_idx]\n",
    "val_data = all_data[train_idx:val_idx, 1:2]\n",
    "val_labels = all_labels[train_idx:val_idx]\n",
    "test_data = all_data[val_idx:test_idx, 1:2]\n",
    "test_labels = all_labels[val_idx:test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727ec5576f759d45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:45.092920Z",
     "start_time": "2025-03-27T19:06:45.087289Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataloader(data, labels, bs, infinite=False):\n",
    "    if not infinite:\n",
    "        for i in range(0, len(data), bs):\n",
    "            yield data[i:i+bs], labels[i:i+bs]\n",
    "    else:\n",
    "        while True:\n",
    "            for i in range(0, len(data), bs):\n",
    "                yield data[i:i+bs], labels[i:i+bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dba3b9701e3c1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:46.227813Z",
     "start_time": "2025-03-27T19:06:45.823408Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot some samples from the datalaoder:\n",
    "for x, y in dataloader(train_data, train_labels, 16):\n",
    "    fig, axs = plt.subplots(2, 4)\n",
    "    for i, ax in enumerate(axs.flat):\n",
    "        ax.imshow(x[i, 0])\n",
    "        ax.set_title(f\"Label: {y[i]}\")\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867cd516df9b28c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:46.277191Z",
     "start_time": "2025-03-27T19:06:46.266283Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(eqx.Module):\n",
    "    conv_layers: list\n",
    "    residual_conv_layers: dict\n",
    "    use_residual: bool\n",
    "    mlp_layers: list\n",
    "    residual_mlp_layers: dict\n",
    "    first_strided_layer: callable\n",
    "    map_to_lsm: callable\n",
    "\n",
    "    def __init__(self, key, conv_layer_channels=(32,64,64,64), mlp_layer_channels=(64,32), use_residual=False, stride_first_layer=1, conv_kwargs={}):\n",
    "        # Standard CNN setup: convolutional layer, followed by flattening,\n",
    "        # with a small MLP on top.\n",
    "        \n",
    "        self.conv_layers=[]\n",
    "        self.mlp_layers = []\n",
    "        \n",
    "        self.residual_conv_layers = {}\n",
    "        self.residual_mlp_layers = {}\n",
    "        self.use_residual = use_residual\n",
    "        num_ch = 3\n",
    "        \n",
    "        key, use_key = jax.random.split(key)\n",
    "        self.first_strided_layer = eqx.nn.Identity() if stride_first_layer == 1 else eqx.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        \n",
    "        layer_counter = 0\n",
    "        for i, ch_next in enumerate(conv_layer_channels):\n",
    "            key, use_key = jax.random.split(key)\n",
    "            self.conv_layers.append(eqx.nn.Conv2d(num_ch, ch_next, kernel_size=3, key=use_key, padding='SAME'))\n",
    "            self.conv_layers.append(jax.nn.silu)    \n",
    "            key, use_key = jax.random.split(key)\n",
    "            self.conv_layers.append(eqx.nn.Conv2d(ch_next, ch_next, kernel_size=3, key=use_key, padding='SAME'))\n",
    "            self.conv_layers.append(jax.nn.silu)  \n",
    "            self.conv_layers.append(eqx.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            layer_counter += 5\n",
    "\n",
    "            if self.use_residual:\n",
    "                key, use_key = jax.random.split(key)\n",
    "                self.residual_conv_layers[layer_counter] = eqx.nn.Conv2d(num_ch, ch_next, kernel_size=2, stride=2, key=use_key)\n",
    "                                                                     \n",
    "            num_ch = ch_next\n",
    "        \n",
    "        layer_counter = 0\n",
    "        for i, ch_next in enumerate(mlp_layer_channels):\n",
    "            key, use_key = jax.random.split(key)\n",
    "            self.mlp_layers.append(eqx.nn.Linear(num_ch, ch_next, key=use_key))\n",
    "            self.mlp_layers.append(jax.nn.silu) \n",
    "            layer_counter += 2\n",
    "            if self.use_residual:\n",
    "                key, use_key = jax.random.split(key)\n",
    "                self.residual_mlp_layers[layer_counter] = eqx.nn.Linear(num_ch, ch_next, key=use_key)\n",
    "            num_ch = ch_next\n",
    "            \n",
    "        key, use_key = jax.random.split(key)\n",
    "        self.map_to_lsm = eqx.nn.Sequential([eqx.nn.Linear(num_ch, 10, key=use_key),\n",
    "                                            eqx.nn.Lambda(jax.nn.log_softmax)])\n",
    "        \n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.get_final_emb(x)\n",
    "        return self.map_to_lsm(x)\n",
    "    \n",
    "    def get_final_emb(self, x):\n",
    "        x = jax.nn.one_hot(x[0], 3)\n",
    "        x = jnp.permute_dims(x, (2,0,1))\n",
    "        x = self.first_strided_layer(x)\n",
    "        last_x_for_residual = x\n",
    "        for i, layer in enumerate(self.conv_layers):\n",
    "            # print(i, layer)\n",
    "            if i in self.residual_conv_layers:\n",
    "                x = x + self.residual_conv_layers[i](last_x_for_residual)\n",
    "                last_x_for_residual = x\n",
    "            x = layer(x)\n",
    "        \n",
    "        x = jnp.mean(x, axis=(-2, -1))\n",
    "        last_x_for_residual = x\n",
    "        \n",
    "        for i, layer in enumerate(self.mlp_layers):\n",
    "            if i in self.residual_mlp_layers:\n",
    "                x = x + self.residual_mlp_layers[i](last_x_for_residual)\n",
    "                last_x_for_residual = x\n",
    "            x = layer(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594dc0e9eb518fb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:49.724810Z",
     "start_time": "2025-03-27T19:06:46.820720Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CNN(jax.random.PRNGKey(SEED), conv_layer_channels=(32,64), mlp_layer_channels=(256,32),\n",
    "            use_residual=USE_RESIDUAL, stride_first_layer=STRIDE_FIRST_LAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162018aa943bd57b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:49.763929Z",
     "start_time": "2025-03-27T19:06:49.748585Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68459953ebc4e3c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:49.942512Z",
     "start_time": "2025-03-27T19:06:49.937528Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy(y, pred_y):\n",
    "    # y are the true targets, and should be integers 0-9.\n",
    "    # pred_y are the log-softmax'd predictions.\n",
    "    pred_y = jnp.take_along_axis(pred_y, jnp.expand_dims(y, 1), axis=1)\n",
    "    return -jnp.mean(pred_y)\n",
    "\n",
    "def loss(model: CNN, x, y):\n",
    "    # Our input has the shape (BATCH_SIZE, 1, 28, 28), but our model operations on\n",
    "    # a single input input image of shape (1, 28, 28).\n",
    "    #\n",
    "    # Therefore, we have to use jax.vmap, which in this case maps our model over the\n",
    "    # leading (batch) axis.\n",
    "    pred_y = jax.vmap(model)(x)\n",
    "\n",
    "    return cross_entropy(y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9aac3bd95e026f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:50.075427Z",
     "start_time": "2025-03-27T19:06:50.068400Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = eqx.filter_jit(loss)\n",
    "\n",
    "@eqx.filter_jit\n",
    "def compute_accuracy(model: CNN, x, y):\n",
    "    \"\"\"This function takes as input the current model\n",
    "    and computes the average accuracy on a batch.\n",
    "    \"\"\"\n",
    "    pred_y = jax.vmap(model)(x)\n",
    "    pred_y = jnp.argmax(pred_y, axis=1)\n",
    "    return jnp.mean(y == pred_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c2c60169e2e61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:50.569962Z",
     "start_time": "2025-03-27T19:06:50.564900Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model: CNN, test_data_iterable):\n",
    "    \"\"\"This function evaluates the model on the test dataset,\n",
    "    computing both the average loss and the average accuracy.\n",
    "    \"\"\"\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    count = 0\n",
    "    for x, y in test_data_iterable:\n",
    "        x = x\n",
    "        y = y\n",
    "        # Note that all the JAX operations happen inside `loss` and `compute_accuracy`,\n",
    "        # and both have JIT wrappers, so this is fast.\n",
    "        avg_loss += loss(model, x, y)\n",
    "        avg_acc += compute_accuracy(model, x, y)\n",
    "        count += 1\n",
    "    return avg_loss / count, avg_acc / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cf1e65b0a392a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:52.712943Z",
     "start_time": "2025-03-27T19:06:51.281017Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(model, dataloader(val_data, val_labels, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b630a6c94f0c82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:52.749688Z",
     "start_time": "2025-03-27T19:06:52.746255Z"
    }
   },
   "outputs": [],
   "source": [
    "optim = optax.adamw(LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7a21a45cdcb5c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:52.797024Z",
     "start_time": "2025-03-27T19:06:52.790804Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: CNN,\n",
    "    train_data_iterable,\n",
    "    train_labels_iterable,\n",
    "    test_data_iterable,\n",
    "    test_labels_iterable,\n",
    "    optim: optax.GradientTransformation,\n",
    "    steps: int,\n",
    "    print_every: int,\n",
    "):\n",
    "    # Just like earlier: It only makes sense to train the arrays in our model,\n",
    "    # so filter out everything else.\n",
    "    opt_state = optim.init(eqx.filter(model, eqx.is_array))\n",
    "\n",
    "    # Always wrap everything -- computing gradients, running the optimiser, updating\n",
    "    # the model -- into a single JIT region. This ensures things run as fast as\n",
    "    # possible.\n",
    "    @eqx.filter_jit\n",
    "    def make_step(\n",
    "        model: CNN,\n",
    "        opt_state,\n",
    "        x,\n",
    "        y,\n",
    "    ):\n",
    "        loss_value, grads = eqx.filter_value_and_grad(loss)(model, x, y)\n",
    "        updates, opt_state = optim.update(\n",
    "            grads, opt_state, eqx.filter(model, eqx.is_array)\n",
    "        )\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        return model, opt_state, loss_value\n",
    "    \n",
    "    trainloader = dataloader(train_data_iterable, train_labels_iterable, BATCH_SIZE, infinite=True)\n",
    "\n",
    "    # # Loop over our training dataset as many times as we need.\n",
    "    # def infinite_trainloader():\n",
    "    #     while True:\n",
    "    #         yield from trainloader\n",
    "\n",
    "    for step, (x, y) in zip(range(steps), trainloader):\n",
    "        tic = time.time()\n",
    "        model, opt_state, train_loss = make_step(model, opt_state, x, y)\n",
    "        toc = time.time()\n",
    "        if (step % print_every) == 0 or (step == steps - 1):\n",
    "            # fig, axs = plt.subplots(2, 4)\n",
    "            # for i, ax in enumerate(axs.flat):\n",
    "            #     ax.imshow(x[i, 0])\n",
    "            #     ax.set_title(f\"Label: {y[i]}\")\n",
    "            #     ax.axis('off')\n",
    "            # plt.show()\n",
    "            testloader = dataloader(test_data_iterable, test_labels_iterable, BATCH_SIZE)\n",
    "            test_loss, test_accuracy = evaluate(model, testloader)\n",
    "            print(\n",
    "                f\"{step=}, train_loss={train_loss.item()}, \"\n",
    "                f\"test_loss={test_loss.item()}, test_accuracy={test_accuracy.item()}\"\n",
    "                f\" time={toc-tic} s\"\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e85d54a70ab0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:53.051243Z",
     "start_time": "2025-03-27T19:06:53.047206Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = train(model, train_data, train_labels, val_data, val_labels, optim, STEPS, PRINT_EVERY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638879767257ff49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:53.369108Z",
     "start_time": "2025-03-27T19:06:53.363520Z"
    }
   },
   "outputs": [],
   "source": [
    "# eqx.tree_serialise_leaves('CPM_MNIST_classifier.eqx', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419c3f67adb3374f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:53.739863Z",
     "start_time": "2025-03-27T19:06:53.412860Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(model, dataloader(test_data, test_labels, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5588bbe001d5d2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:54.299213Z",
     "start_time": "2025-03-27T19:06:54.295359Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa14197cffd63cd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:54.756877Z",
     "start_time": "2025-03-27T19:06:54.753101Z"
    }
   },
   "outputs": [],
   "source": [
    "  ### load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6026ac682e15e5ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:54.814262Z",
     "start_time": "2025-03-27T19:06:54.790004Z"
    }
   },
   "outputs": [],
   "source": [
    "model = eqx.tree_deserialise_leaves('CPM_MNIST_classifier.eqx', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2019b44efe9b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:06:56.163754Z",
     "start_time": "2025-03-27T19:06:55.832922Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(model, dataloader(test_data, test_labels, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e039f812a52c0c04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:07:07.724596Z",
     "start_time": "2025-03-27T19:07:07.719221Z"
    }
   },
   "outputs": [],
   "source": [
    "# now calculate the inception score with the model on the training data itself:\n",
    "\n",
    "def inception_score(model, data, labels, bs, num_samples=1000):\n",
    "    # sample num_samples images from the data\n",
    "    idx = np.random.choice(len(data), num_samples, replace=False)\n",
    "    data = data[idx]\n",
    "    labels = labels[idx]\n",
    "    loader = dataloader(data, labels, bs)\n",
    "    preds = []\n",
    "    for x, y in loader:\n",
    "        pred = jax.vmap(model)(x)\n",
    "        preds.append(pred)\n",
    "    preds = jnp.concatenate(preds)\n",
    "    preds = jnp.exp(preds)  # from log_softmax to softmax\n",
    "    preds = preds / jnp.sum(preds, axis=1, keepdims=True)\n",
    "    kl_divs = jnp.sum(preds * (jnp.log(preds + 1e-6) - jnp.log(jnp.mean(preds, axis=0))), axis=1)\n",
    "    return jnp.exp(jnp.mean(kl_divs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13122f28f175f5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:07:14.454967Z",
     "start_time": "2025-03-27T19:07:08.991091Z"
    }
   },
   "outputs": [],
   "source": [
    "IS = inception_score(model, train_data, train_labels, 32, len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2c924ec6062e77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:07:14.482094Z",
     "start_time": "2025-03-27T19:07:14.476576Z"
    }
   },
   "outputs": [],
   "source": [
    "print(IS)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c72eb54e08d87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:07:17.801931Z",
     "start_time": "2025-03-27T19:07:17.794954Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582daced8b923a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:07:18.439372Z",
     "start_time": "2025-03-27T19:07:18.434780Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b69d826cfeaf22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:07:18.804050Z",
     "start_time": "2025-03-27T19:07:18.799483Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55992314fe1671c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:07:20.333518Z",
     "start_time": "2025-03-27T19:07:20.328997Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bba6fe05a90d247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:07:30.788038Z",
     "start_time": "2025-03-27T19:07:21.107988Z"
    }
   },
   "outputs": [],
   "source": [
    "# load samples:\n",
    "def shuffle(arr):\n",
    "    idx = np.random.choice(np.arange(arr.shape[0]), replace=False, size=arr.shape[0])\n",
    "    return arr[idx]\n",
    "\n",
    "\n",
    "paths = []\n",
    "for p in os.listdir('Exp1/cpm/'):\n",
    "    if p.endswith('.eqx'):\n",
    "        files = os.listdir(os.path.join('Exp1/cpm/', p))\n",
    "        for f in files:\n",
    "            if f.endswith('.npz'):\n",
    "                paths.append(os.path.join('Exp1/cpm/', p, f))\n",
    "\n",
    "\n",
    "datas = {}\n",
    "samples = {}\n",
    "energies = {}\n",
    "for path in paths:\n",
    "    data = np.load(path)\n",
    "    datas[path] = data\n",
    "    samples[path] = data['all_samples']\n",
    "    energies[path] = data['all_energies']\n",
    "    print(path, samples[path].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208dfaac70e68cc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:07:30.837454Z",
     "start_time": "2025-03-27T19:07:30.829867Z"
    }
   },
   "outputs": [],
   "source": [
    "samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ab9beb759d99a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:07:35.042688Z",
     "start_time": "2025-03-27T19:07:30.985327Z"
    }
   },
   "outputs": [],
   "source": [
    "print('INCEPTION SCORES - higher is better\\n')\n",
    "for k, v in samples.items():\n",
    "    sample = v\n",
    "    # print(v.shape)\n",
    "    samples_type = sample[:, -1, 1:2]\n",
    "    IS_samples = inception_score(model, samples_type, np.zeros(len(samples_type)), 16, len(samples_type))\n",
    "    print(k.split('/')[-2], '\\t\\t', float(np.round(IS_samples, 2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafab93d7b2a9d55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:07:56.704112Z",
     "start_time": "2025-03-27T19:07:56.698804Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac30561201ebd67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:07:57.260562Z",
     "start_time": "2025-03-27T19:07:57.257074Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df2500f7eb055e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:08:02.548176Z",
     "start_time": "2025-03-27T19:07:59.424099Z"
    }
   },
   "outputs": [],
   "source": [
    "for k, v in samples.items():\n",
    "    sample = v\n",
    "    samples_type = sample[:, -1, 1:2]\n",
    "    preds = jax.vmap(model)(samples_type).argmax(axis=1)\n",
    "    print(k, np.unique(preds, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02e66b2b039828",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:08:04.909079Z",
     "start_time": "2025-03-27T19:08:02.588243Z"
    }
   },
   "outputs": [],
   "source": [
    "print('plotting real data trajectories')\n",
    "num_samples = 10\n",
    "ts_to_plot = [1, 4, 7, 10, 13, 16, 19]\n",
    "some_data_incl_time, _ = load_data_batch_for_classifier(num_samples,\n",
    "        '../data/MNIST_jaxCPM_data', t=None, )\n",
    "fig, axs = plt.subplots(num_samples, len(ts_to_plot), figsize=(10, num_samples))\n",
    "\n",
    "utils.plot_cell_trajectory_data(some_data_incl_time, num_samples, ts_to_plot, axs, colors=colors)\n",
    "for ax in axs.flat: ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2aefaed128b45f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:08:20.680355Z",
     "start_time": "2025-03-27T19:08:05.499459Z"
    }
   },
   "outputs": [],
   "source": [
    "# qualitative plots for true and generated samples:\n",
    "stepsize = 20\n",
    "max_steps = 1000\n",
    "num_samples_to_plot = 10\n",
    "if 'real_data' in samples:\n",
    "    samples.pop('real_data')\n",
    "for k, v in samples.items():\n",
    "    \n",
    "    name = k.split('/')[-2]\n",
    "    sample = v\n",
    "    print(name)\n",
    "    data_to_plot = shuffle(sample)[0:num_samples_to_plot] #[shuffle(some_data_incl_time)[0:1]]\n",
    "\n",
    "    ts_to_plot = [i * stepsize for i in range(min(data_to_plot.shape[1] // stepsize, max_steps))]\n",
    "    fig, axs = plt.subplots(data_to_plot.shape[0], len(ts_to_plot), figsize=(len(ts_to_plot)*2, len(samples.items())), squeeze=False)\n",
    "    \n",
    "    utils.plot_cell_trajectory_data(data_to_plot, num_samples, ts_to_plot, axs)\n",
    "    \n",
    "    for ax in axs.flat: ax.axis('off')\n",
    "    # for i, row in enumerate(axs):\n",
    "    #     row[0].set_ylabel(names[i])\n",
    "    #     print(row[0].get_ylabel())\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fc581f2d704e3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T14:38:59.531769Z",
     "start_time": "2025-01-30T14:38:55.938837Z"
    }
   },
   "outputs": [],
   "source": [
    "# a single plot with one qualitative example for each model:\n",
    "\n",
    "# qualitative plots for true and generated samples:\n",
    "stepsize = 20\n",
    "max_steps = 1000\n",
    "num_samples_to_plot = 10\n",
    "if 'real_data' in samples:\n",
    "    samples.pop('real_data')\n",
    "\n",
    "data_to_plot = []\n",
    "names_of_models = ['experiment_1_cellsort_4990.eqx', 'experiment_1_extpot_4990.eqx', 'experiment_1_conv_ham_850.eqx',\n",
    "                   'experiment_1_shallow_nh_6250.eqx', 'experiment_1_nh_5650.eqx', 'experiment_1_nch_agg_downsample_8660.eqx']\n",
    "names_to_plot = ['Cellsort\\nHamiltonian', 'Cellsort\\nHamiltonian\\n+External\\nPotential', 'CNN', '1 NH layer\\n+CNN',\n",
    "                 'Neural\\nHamiltonian', 'Neural\\nHamiltonian\\n+closure']\n",
    "\n",
    "keys = list(samples.keys())\n",
    "\n",
    "for name in names_of_models:\n",
    "    k = list(filter(lambda x: name in x, keys))[0]\n",
    "    print(name, k)\n",
    "    v = samples[k]\n",
    "    sample = v\n",
    "    data_this = shuffle(sample)[0:1] #[shuffle(some_data_incl_time)[0:1]]\n",
    "    data_to_plot.append(data_this)\n",
    "\n",
    "data_to_plot = np.concatenate(data_to_plot, axis=0)\n",
    "\n",
    "# ts_to_plot = [i * stepsize for i in range(min(data_to_plot.shape[1] // stepsize, max_steps))]\n",
    "ts_to_plot = [0, 24, 48, 72, 96]\n",
    "ts_to_display =  [0, 200, 400, 600, 800]\n",
    "\n",
    "mcs_correction_factor = 2/3 * 13.1  \n",
    "#2/3: we saved at each 2/3 *h*w spin flip attempts -- 13.1: correction factor since we only sampled on the boundary of the pixels\n",
    "\n",
    "fig, axs = plt.subplots(len(samples.items()), len(ts_to_plot), figsize=(len(ts_to_plot)*1, len(samples.items())), squeeze=False, gridspec_kw={'wspace': 0.05, 'hspace': 0.05})\n",
    "\n",
    "utils.plot_cell_trajectory_data(data_to_plot, num_samples, ts_to_plot, axs, colors=colors)\n",
    "\n",
    "\n",
    "# Adjust axis labels and formatting\n",
    "for i, ax_row in enumerate(axs):\n",
    "    for j, ax in enumerate(ax_row):\n",
    "        ax.axis(\"on\")  # Explicitly enable axes for adding labels\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if j == 0:  # Add row labels to the left of the subplots\n",
    "            ax.set_ylabel(\n",
    "                names_to_plot[i], fontsize=8, labelpad=20, \n",
    "                rotation=90, va=\"center\", ha=\"center\"\n",
    "            )\n",
    "        if i == len(axs) - 1:  # Add x-axis labels below the bottom row\n",
    "            ax.set_xlabel(f\"{int(ts_to_display[j])}\", fontsize=8, labelpad=10)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout(rect=[0.05, 0.05, 0.05, 0.05])  # Leave space for labels\n",
    "\n",
    "# Add a global x-axis label for time in seconds\n",
    "fig.text(0.5, 0.04, 'Time (MCS)', ha='center', va='center', fontsize=9)\n",
    "plt.savefig(FIGURE_SAVEDIR+'traj_exp1.pdf', dpi=400, transparent=True)\n",
    "plt.show()\n",
    "\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb6d8efc29d666",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:19:08.797643Z",
     "start_time": "2025-03-27T19:19:05.687245Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rebuttal plots:\n",
    "\n",
    "# a single plot with one qualitative example for each model:\n",
    "\n",
    "# qualitative plots for true and generated samples:\n",
    "stepsize = 20\n",
    "max_steps = 1000\n",
    "num_samples_to_plot = 10\n",
    "if 'real_data' in samples:\n",
    "    samples.pop('real_data')\n",
    "\n",
    "data_to_plot = []\n",
    "names_of_models = 2*['experiment_1_closure_gnn_seed42_9950.eqx'] + 2*['experiment_1_nch_no_interactions_9950.eqx'] + 2*['experiment_1_nch_no_pooling_3750.eqx']\n",
    "names_to_plot = 2*['GNN\\n+ closure'] + 2*['NH + closure\\nno interactions'] + 2*['NH + closure\\nno pooling']\n",
    "keys = list(samples.keys())\n",
    "\n",
    "for name in names_of_models:\n",
    "    k = list(filter(lambda x: name in x, keys))[0]\n",
    "    print(name, k)\n",
    "    v = samples[k]\n",
    "    sample = v\n",
    "    data_this = shuffle(sample)[0:1] #[shuffle(some_data_incl_time)[0:1]]\n",
    "    data_to_plot.append(data_this)\n",
    "\n",
    "data_to_plot = np.concatenate(data_to_plot, axis=0)\n",
    "\n",
    "# ts_to_plot = [i * stepsize for i in range(min(data_to_plot.shape[1] // stepsize, max_steps))]\n",
    "ts_to_plot = [0, 24, 48, 72, 96]\n",
    "ts_to_display =  [0, 200, 400, 600, 800]\n",
    "\n",
    "mcs_correction_factor = 2/3 * 13.1  \n",
    "#2/3: we saved at each 2/3 *h*w spin flip attempts -- 13.1: correction factor since we only sampled on the boundary of the pixels\n",
    "\n",
    "fig, axs = plt.subplots(len(names_of_models), len(ts_to_plot), figsize=(len(ts_to_plot)*1, len(names_of_models)+0.75), squeeze=False, gridspec_kw={'wspace': 0.05, 'hspace': 0.05})\n",
    "\n",
    "utils.plot_cell_trajectory_data(data_to_plot, num_samples, ts_to_plot, axs, colors=colors)\n",
    "\n",
    "\n",
    "# Adjust axis labels and formatting\n",
    "for i, ax_row in enumerate(axs):\n",
    "    for j, ax in enumerate(ax_row):\n",
    "        ax.axis(\"on\")  # Explicitly enable axes for adding labels\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if j == 0:  # Add row labels to the left of the subplots\n",
    "            ax.set_ylabel(\n",
    "                names_to_plot[i], fontsize=8, labelpad=20, \n",
    "                rotation=90, va=\"center\", ha=\"center\"\n",
    "            )\n",
    "        if i == len(axs) - 1:  # Add x-axis labels below the bottom row\n",
    "            ax.set_xlabel(f\"{int(ts_to_display[j])}\", fontsize=8, labelpad=10)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout(rect=[0.05, 0.05, 0.05, 0.05])  # Leave space for labels\n",
    "\n",
    "# Add a global x-axis label for time in seconds\n",
    "fig.text(0.5, 0.04, 'Time (MCS)', ha='center', va='center', fontsize=9)\n",
    "plt.savefig(FIGURE_SAVEDIR+'traj_exp1_rebuttal.jpg', dpi=400, transparent=True)\n",
    "plt.show()\n",
    "\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd377ce0b222f22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T14:41:03.527224Z",
     "start_time": "2025-01-30T14:40:53.751875Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(FIGURE_SAVEDIR, 'add_qual_exp1')):\n",
    "    os.makedirs(os.path.join(FIGURE_SAVEDIR, 'add_qual_exp1'))\n",
    "# a single plot with one qualitative example for each model:\n",
    "for plot_id in range(4):\n",
    "    # qualitative plots for true and generated samples:\n",
    "    stepsize = 20\n",
    "    max_steps = 1000\n",
    "    num_samples_to_plot = 10\n",
    "    if 'real_data' in samples:\n",
    "        samples.pop('real_data')\n",
    "    \n",
    "    data_to_plot = []\n",
    "    names_of_models = ['experiment_1_cellsort_4990.eqx', 'experiment_1_extpot_4990.eqx', 'experiment_1_conv_ham_850.eqx',\n",
    "                       'experiment_1_shallow_nh_6250.eqx', 'experiment_1_nh_5650.eqx', 'experiment_1_nch_agg_downsample_8660.eqx']\n",
    "    names_to_plot = ['Cellsort\\nHamiltonian', 'Cellsort\\nHamiltonian\\n+External\\nPotential', 'CNN', '1 NH layer\\n+CNN',\n",
    "                     'Neural\\nHamiltonian', 'Neural\\nHamiltonian\\n+closure']\n",
    "    \n",
    "    keys = list(samples.keys())\n",
    "    \n",
    "    for name in names_of_models:\n",
    "        k = list(filter(lambda x: name in x, keys))[0]\n",
    "        print(name, k)\n",
    "        v = samples[k]\n",
    "        sample = v\n",
    "        data_this = shuffle(sample)[0:1] #[shuffle(some_data_incl_time)[0:1]]\n",
    "        data_to_plot.append(data_this)\n",
    "    \n",
    "    data_to_plot = np.concatenate(data_to_plot, axis=0)\n",
    "    \n",
    "    # ts_to_plot = [i * stepsize for i in range(min(data_to_plot.shape[1] // stepsize, max_steps))]\n",
    "    ts_to_plot = [0, 24, 48, 72, 96]\n",
    "    ts_to_display =  [0, 200, 400, 600, 800]\n",
    "    \n",
    "    mcs_correction_factor = 2/3 * 13.1  \n",
    "    #2/3: we saved at each 2/3 *h*w spin flip attempts -- 13.1: correction factor since we only sampled on the boundary of the pixels\n",
    "    \n",
    "    fig, axs = plt.subplots(len(samples.items()), len(ts_to_plot), figsize=(len(ts_to_plot)*1, len(samples.items())), squeeze=False, gridspec_kw={'wspace': 0.05, 'hspace': 0.05})\n",
    "    \n",
    "    utils.plot_cell_trajectory_data(data_to_plot, num_samples, ts_to_plot, axs, colors=colors)\n",
    "    \n",
    "    \n",
    "    # Adjust axis labels and formatting\n",
    "    for i, ax_row in enumerate(axs):\n",
    "        for j, ax in enumerate(ax_row):\n",
    "            ax.axis(\"on\")  # Explicitly enable axes for adding labels\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            if j == 0:  # Add row labels to the left of the subplots\n",
    "                ax.set_ylabel(\n",
    "                    names_to_plot[i], fontsize=8, labelpad=20, \n",
    "                    rotation=90, va=\"center\", ha=\"center\"\n",
    "                )\n",
    "            if i == len(axs) - 1:  # Add x-axis labels below the bottom row\n",
    "                ax.set_xlabel(f\"{int(ts_to_display[j])}\", fontsize=8, labelpad=10)\n",
    "    \n",
    "    # Adjust layout and show the plot\n",
    "    plt.tight_layout(rect=[0.05, 0.05, 0.05, 0.05])  # Leave space for labels\n",
    "    \n",
    "    # Add a global x-axis label for time in seconds\n",
    "    fig.text(0.5, 0.04, 'Time (MCS)', ha='center', va='center', fontsize=9)\n",
    "    plt.savefig(os.path.join(FIGURE_SAVEDIR, 'add_qual_exp1', f'traj_exp1_{plot_id}.pdf'), dpi=400, transparent=True)\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7addc28809d92a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T14:09:13.896417Z",
     "start_time": "2025-01-30T14:09:13.891656Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139d28d1239bedc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T14:09:14.162012Z",
     "start_time": "2025-01-30T14:09:14.156407Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8dd4f09612aaa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T12:46:53.207015Z",
     "start_time": "2025-01-24T12:46:53.200667Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0542c5f80054d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:59:40.157499Z",
     "start_time": "2025-01-24T10:59:40.154052Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9d4eec3806f08f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:17:59.870181Z",
     "start_time": "2025-01-24T10:17:59.867008Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1925605dd4e576",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:18:00.035494Z",
     "start_time": "2025-01-24T10:18:00.032337Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750391dfbc774389",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:18:00.186620Z",
     "start_time": "2025-01-24T10:18:00.183559Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167eab704e8689d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:18:00.506736Z",
     "start_time": "2025-01-24T10:18:00.500757Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8441eb9dd84ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:18:01.195064Z",
     "start_time": "2025-01-24T10:18:01.191763Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff439fd04fe6ad18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:18:01.410545Z",
     "start_time": "2025-01-24T10:18:01.407627Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afdb49ab1f87e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:18:01.629949Z",
     "start_time": "2025-01-24T10:18:01.626364Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384f2d858f5a600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:18:01.857309Z",
     "start_time": "2025-01-24T10:18:01.853505Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa17288acec87907",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:18:02.091317Z",
     "start_time": "2025-01-24T10:18:02.086957Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be163347c94da84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:08:32.878781Z",
     "start_time": "2025-03-27T19:08:31.136431Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the stable states:\n",
    "\n",
    "num_cells = len(np.unique(all_data[:,0]))\n",
    "volumes = jax.vmap(utils.calculate_all_cell_volumes, in_axes=(0, None))(all_data, num_cells)[:, 1:] # ignore medium\n",
    "\n",
    "vol_low, vol_high = np.min(volumes), np.max(volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd30439fe8eeaf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:08:32.969436Z",
     "start_time": "2025-03-27T19:08:32.964015Z"
    }
   },
   "outputs": [],
   "source": [
    "print(vol_low, vol_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607144f29f3f4ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:08:33.607779Z",
     "start_time": "2025-03-27T19:08:33.601426Z"
    }
   },
   "outputs": [],
   "source": [
    "samples['real_data'] = all_data[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2e52387339c72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:11:25.526760Z",
     "start_time": "2025-03-27T19:08:33.718158Z"
    }
   },
   "outputs": [],
   "source": [
    "stable_dict = {}\n",
    "frag_dict = {}\n",
    "vol_dict = {}\n",
    "\n",
    "from scipy.ndimage import label\n",
    "neighborhood_order = 4\n",
    "\n",
    "\n",
    "def calc_frag_batched(samples, num_cells, neighborhood_order): # this is not transformable under jax unfortunately\n",
    "    num_fragmented = np.zeros(samples.shape[0])\n",
    "    for i, sample in enumerate(samples):\n",
    "        num_fragmented[i] = utils.count_num_fragmented(sample, num_cells, neighborhood_order)\n",
    "    return num_fragmented\n",
    "\n",
    "# calc_frag_batched = eqx.filter_jit(jax.vmap(\n",
    "#             utils.count_num_fragmented, in_axes=(0, None, None)\n",
    "#         ))\n",
    "calc_vol_batched = eqx.filter_jit(jax.vmap(\n",
    "            utils.calculate_all_cell_volumes, in_axes=(0, None)\n",
    "        ))\n",
    "for k, v in samples.items():\n",
    "    print(k)\n",
    "    sample = v\n",
    "    stable_times = []\n",
    "    frag_times = []\n",
    "    vol_times = []\n",
    "    for t in tqdm(range(0, sample.shape[1], 5)):\n",
    "        # stable = calc_stable_batched(sample[:, t], num_cells, vol_low, vol_high, 0, 0, 2)\n",
    "        frag = calc_frag_batched(np.array(sample[:, t]), num_cells, neighborhood_order)\n",
    "        vol = calc_vol_batched(sample[:, t], num_cells)[:, 1:]\n",
    "        # stable_times.append(stable[:, None, ...])\n",
    "        frag_times.append(frag[:, None, ...])\n",
    "        vol_times.append(vol[:, None, ...])\n",
    "    # stable_dict[k] = np.concatenate(stable_times, axis=1)\n",
    "    frag_dict[k] = np.concatenate(frag_times, axis=1)\n",
    "    vol_dict[k] = np.concatenate(vol_times, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b67cef1ce1d2b81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:50:43.483886Z",
     "start_time": "2025-01-24T10:50:43.480399Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb4b38024bd2303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T10:50:43.514880Z",
     "start_time": "2025-01-24T10:50:43.512065Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377746f8d9fb5027",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:11:26.404349Z",
     "start_time": "2025-03-27T19:11:25.565144Z"
    }
   },
   "outputs": [],
   "source": [
    "min_vol = vol_low - 10\n",
    "max_vol = vol_high + 10\n",
    "max_num_vol_violate = 0\n",
    "max_num_fragmented = 3\n",
    "\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "\n",
    "for k, v in frag_dict.items():\n",
    "    num_frag = v\n",
    "    vol = vol_dict[k]\n",
    "    vol_good = jnp.logical_or((vol < min_vol), (vol > max_vol)).sum(-1) <= max_num_vol_violate\n",
    "    frag_good = num_frag <= max_num_fragmented\n",
    "    stable = jnp.logical_and(frag_good, vol_good)\n",
    "    # stable = np.cumprod(stable, axis=1)\n",
    "    ax[0].plot(stable.mean(0), label=k)\n",
    "    # put legend above plot\n",
    "    ax[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), shadow=True, ncol=2)\n",
    "    ax[1].plot(vol_good.mean(0))\n",
    "    ax[2].plot(frag_good.mean(0))\n",
    "    name = k.split('/')[-2] if '/' in k else k\n",
    "    print(name, 'vol: ', vol_good.mean(), 'frag: ',frag_good.mean(), 'stable: ',stable.mean())\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbbb698b60f56d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T16:37:59.207267Z",
     "start_time": "2025-01-06T16:37:58.687459Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7cadcc16d54e40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T16:38:08.768247Z",
     "start_time": "2025-01-06T16:38:08.764529Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c656c531ab99fc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T16:38:09.531427Z",
     "start_time": "2025-01-06T16:38:09.522649Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f27c33e98921d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T16:38:11.463488Z",
     "start_time": "2025-01-06T16:38:11.457799Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ed875788f168c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T16:38:16.741956Z",
     "start_time": "2025-01-06T16:38:16.736779Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d693996cbdcc832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T16:39:05.836690Z",
     "start_time": "2025-01-06T16:39:01.891041Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67022bd8bd5e269",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T16:39:05.877318Z",
     "start_time": "2025-01-06T16:39:05.870523Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab71ba74940de3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T16:39:05.999838Z",
     "start_time": "2025-01-06T16:39:05.990132Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06a8fccb0bc473d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
