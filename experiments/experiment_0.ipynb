{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# get the runs from wandb:\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import wandb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# plotting:\n",
    "from tueplots import bundles\n",
    "from tueplots import figsizes\n",
    "\n",
    "import utils\n",
    "\n",
    "bundle = bundles.icml2024()\n",
    "bundle['text.usetex'] = False\n",
    "bundle.pop('text.latex.preamble')\n",
    "plt.rcParams.update(bundle)\n",
    "\n",
    "\n",
    "FIGURE_SAVEDIR = 'Experiment_figures/'\n",
    "if not os.path.exists(FIGURE_SAVEDIR):\n",
    "    os.makedirs(FIGURE_SAVEDIR)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load two datapoints from scenarios a and b and plot them:\n",
    "\n",
    "path = '../data/Exp_0_jaxcpm'\n",
    "\n",
    "datas = []\n",
    "for scenario in ['scenario_a', 'scenario_b', 'scenario_d', 'scenario_f']:\n",
    "    for i in range(1,2):\n",
    "        data = utils.load_data_from_file(os.path.join(path, scenario, f'all_cpms_{i}.npz'))[-1]\n",
    "        datas.append(data)\n",
    "\n"
   ],
   "id": "a1427a685c2cae6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot the data:\n",
    "colors = [\n",
    "            np.array([[0.,0.,0.]]),# black\n",
    "            np.array([[0.,0.,0.25]]),# dark blue\n",
    "            np.array([[1.,0.,0.]]), #  red\n",
    "            np.array([[204.,255.,11.]]) / 255. #  light green\n",
    "        ]\n",
    "\n",
    "\n",
    "types = ['Type A', 'Type B', 'Type D', 'Type F']\n",
    "fig, axs = plt.subplots(1, 4, figsize=(4, 1.), gridspec_kw={'wspace': 0.05, 'hspace': 0.05})\n",
    "\n",
    "for i, data in enumerate(datas):\n",
    "    ax = axs[i]\n",
    "    utils.plot_cell_image(data, ax, colors=colors)\n",
    "    ax.axis('on')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # ax.set_xlabel(types[i])\n",
    "\n",
    "# # Add the text \"Type A\" and \"Type B\" and \"Type D\" and \"Type F\" under each subplot using fig.text:\n",
    "fig.text(0.225, 0.05, 'Type A', ha='center', va='center', fontsize=8)\n",
    "fig.text(0.42, 0.05, 'Type B', ha='center', va='center', fontsize=8)\n",
    "fig.text(0.615, 0.05, 'Type D', ha='center', va='center', fontsize=8)\n",
    "fig.text(0.81, 0.05, 'Type F', ha='center', va='center', fontsize=8)\n",
    "\n",
    "axs[0].set_ylabel(\n",
    "            '\\nCell sorting', fontsize=8, labelpad=10,\n",
    "            rotation=90, va=\"center\", ha=\"center\"\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURE_SAVEDIR + 'exp0_data.png', transparent=True, dpi=400)\n",
    "plt.show()"
   ],
   "id": "cf61ad6cef12ced0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "datas[0].shape",
   "id": "b7be62e36a653cee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "datas[0][0].max()",
   "id": "9e00ebbad1a67784",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "92f77036db101737",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bc6080be859a18bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "wandb.login()",
   "id": "a0444d5ee7ce4351",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "api = wandb.Api()\n",
    "entity, project = 'neuralcpm', 'NeuralCPM'\n",
    "runs = api.runs(entity + \"/\" + project)\n"
   ],
   "id": "6dd55a0356ae8e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# summary_list, config_list, name_list = [], [], []\n",
    "# for run in runs:\n",
    "#     # .summary contains output keys/values for\n",
    "#     # metrics such as accuracy.\n",
    "#     #  We call ._json_dict to omit large files\n",
    "#     summary_list.append(run.summary._json_dict)\n",
    "#\n",
    "#     # .config contains the hyperparameters.\n",
    "#     #  We remove special values that start with _.\n",
    "#     config_list.append({k: v for k, v in run.config.items() if not k.startswith(\"_\")})\n",
    "#\n",
    "#     # .name is the human-readable name of the run.\n",
    "#     name_list.append(run.name)"
   ],
   "id": "9e30a9368591deb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dict_with_dfs = {}\n",
    "for run in runs:\n",
    "    if 'Exp0/' in run.name:\n",
    "        dict_with_dfs[run.name] = run.history()"
   ],
   "id": "9e7d03dee6e77731",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "true_parameters = {\n",
    "    'Sce_a': pd.DataFrame(dict(\n",
    "        lamb_vol=[0.1],\n",
    "        J_0_0=[0.],\n",
    "        J_0_1=[0.5],\n",
    "        J_0_2=[0.5],\n",
    "        J_1_1=[0.333333],\n",
    "        J_1_2=[0.2],\n",
    "        J_2_2=[0.266667]\n",
    "    )),\n",
    "    'Sce_b': pd.DataFrame(dict(\n",
    "        lamb_vol=[0.5],\n",
    "        J_0_0=[0.],\n",
    "        J_0_1=[2.5],\n",
    "        J_0_2=[1.],\n",
    "        J_1_1=[1.],\n",
    "        J_1_2=[4.5],\n",
    "        J_2_2=[1.]\n",
    "    )),\n",
    "    'Sce_d':pd.DataFrame({\n",
    "            'lamb_vol': [0.1],\n",
    "            'J_0_0': [0.],\n",
    "            'J_0_1': [15],\n",
    "            'J_0_2': [7.5],\n",
    "            'J_1_1': [4.],\n",
    "            'J_1_2': [7.5],\n",
    "            'J_2_2': [4.],\n",
    "        }\n",
    "    ),\n",
    "    'Sce_f':pd.DataFrame({\n",
    "            'lamb_vol': [0.05],\n",
    "            'J_0_0': [0.],\n",
    "            'J_0_1': [2],\n",
    "            'J_0_2': [8],\n",
    "            'J_1_1': [7.],\n",
    "            'J_1_2': [5.5],\n",
    "            'J_2_2': [3.],\n",
    "        }\n",
    "    )\n",
    "}"
   ],
   "id": "81203fc11729fb0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "true_parameters['Sce_d']",
   "id": "c84ed546b817bb24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fit_T_and_calc_error(scenario, sampler, dict_with_dfs, true_parameters, key=None):\n",
    "    \"\"\"\n",
    "    As the temperature parameter might be poorly identifiable from static data, and also depend on the sampler, we fit the optimal\n",
    "    multiply the parameters with a scalar s.t. the error is minimized (i.e., we fit the (inverse) optimal temperature).\n",
    "    :param scenario:\n",
    "    :param sampler:\n",
    "    :param dict_with_dfs:\n",
    "    :param true_parameters:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if key is None:\n",
    "        key = f'Exp0/{scenario}/{sampler}'\n",
    "\n",
    "    vals_learned = dict_with_dfs[key][true_parameters[scenario[:5]].columns].values.T\n",
    "    vals_true = true_parameters[scenario[:5]].values.T\n",
    "    T_opt, SSE, rank, singval = np.linalg.lstsq(vals_true, vals_learned, rcond=None)\n",
    "    SSE_nofit = np.linalg.norm(vals_true - vals_learned, axis=0)**2\n",
    "    MSE = SSE / vals_true.shape[1]\n",
    "    MSE_nofit = SSE_nofit / vals_true.shape[1]\n",
    "    return T_opt[0], MSE, MSE_nofit"
   ],
   "id": "b881a0be78da0b7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dict_with_dfs.keys()\n",
   "id": "8a8b76554ba9ad74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sampler_names = ['cpm',\n",
    "                 ]\n",
    "scenarios_samplers = []\n",
    "for key in dict_with_dfs.keys():\n",
    "    for n in sampler_names:\n",
    "        if n in key:\n",
    "            scenarios_samplers.append(\"/\".join(key.split('/')[1:]))\n",
    "\n",
    "\n",
    "scenarios = ['Sce_a', 'Sce_b', 'Sce_d_seed0', 'Sce_f_seed0']\n",
    "\n"
   ],
   "id": "91295ca6347fafba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9643162b00ea4bec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "for scenario in scenarios:\n",
    "    plt.figure()\n",
    "    for scenario_sampler in scenarios_samplers:\n",
    "        if scenario in scenario_sampler and 'mcs' not in scenario_sampler:\n",
    "            sampler = scenario_sampler.split('/')[-1]\n",
    "            print(scenario, sampler)\n",
    "            T, MSE, MSE_nofit = fit_T_and_calc_error(scenario, sampler, dict_with_dfs, true_parameters)\n",
    "            print('logRMSE - T=T*', scenario, sampler, np.log10(np.sqrt(MSE[-1])))\n",
    "            print('logRMSE - T=1', scenario, sampler, np.log10(np.sqrt(MSE_nofit[-1])))\n",
    "            plt.plot(MSE,label=f'{sampler}')\n",
    "    plt.yscale('log')\n",
    "    # plt.ylim(1e-3, 1e1)\n",
    "    plt.title(scenario)\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()"
   ],
   "id": "948586b754c9008d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "for scenario in scenarios:\n",
    "    plt.figure()\n",
    "    for scenario_sampler in scenarios_samplers:\n",
    "        if scenario in scenario_sampler and 'mcs' not in scenario_sampler:\n",
    "            sampler = scenario_sampler.split('/')[-1]\n",
    "            print(scenario, sampler)\n",
    "            T, MSE, MSE_nofit = fit_T_and_calc_error(scenario, sampler, dict_with_dfs, true_parameters)\n",
    "            print('MSE - T=T*', scenario, sampler, np.log10(np.sqrt(MSE[-1])))\n",
    "            print('MSE - T=1', scenario, sampler, np.log10(np.sqrt(MSE_nofit[-1])))\n",
    "            plt.plot(MSE, label=f'{sampler}')\n",
    "            results.append({\n",
    "                'scenario': scenario,\n",
    "                'sampler': sampler,\n",
    "                'log-RMSE ($T=1$)': np.log10(np.sqrt(MSE_nofit[-1])),\n",
    "                'log-RMSE ($T=T^*$)': np.log10(np.sqrt(MSE[-1]))\n",
    "            })\n",
    "    plt.yscale('log')\n",
    "    # plt.ylim(1e-3, 1e1)\n",
    "    plt.title(scenario)\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()\n",
    "\n",
    "results_df = pd.DataFrame(results)"
   ],
   "id": "3c03449dc4017c14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(results_df.set_index(['scenario', 'sampler']).unstack(0).swaplevel(axis=1).sort_index(level=0, axis=1).to_latex(column_format='ccccc'))",
   "id": "334efe2620b6813e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dict_with_dfs.keys()",
   "id": "1b1108c36c09a1c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scenario = 'Sce_b'\n",
    "sampler = 'gwg_0.5mcs'\n",
    "sampler_base = sampler.split('_')[0]\n",
    "k = f'Exp0/{scenario}/{sampler}'\n"
   ],
   "id": "56fa635a565d6d81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "plt.figure()\n",
    "for sampler in ['cpm']: # sampler_names\n",
    "    mcs_sampler = []\n",
    "    mse_sampler = []\n",
    "    for k in dict_with_dfs.keys():\n",
    "        if sampler in k and scenario in k:\n",
    "            print(k)\n",
    "            df = dict_with_dfs[k]\n",
    "            mcs = df['num steps'][0] * 100 / 200**2\n",
    "            T, MSE, MSE_nofit = fit_T_and_calc_error(scenario, sampler, dict_with_dfs, true_parameters, key=k)\n",
    "            MSE_final = MSE[-1]\n",
    "            print('MSE - T=T*', scenario, sampler, mcs, MSE_final)\n",
    "            print('MSE - T=1)', scenario, sampler, mcs, MSE_nofit[-1])\n",
    "            mcs_sampler.append(mcs)\n",
    "            mse_sampler.append(MSE_final)\n",
    "    idx_sort = np.argsort(np.array(mcs_sampler))\n",
    "    plt.plot(np.array(mcs_sampler)[idx_sort], np.array(mse_sampler)[idx_sort], '-o', label=sampler)\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('MCS per training step')\n",
    "plt.show()"
   ],
   "id": "aef0ad8be0c0bf4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dict_with_dfs.keys()",
   "id": "77cd0bfba3a87da2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for all J_*_* values, plot their convergence to the true value for the cpm sampler:\n",
    "\n",
    "scenarios = [\n",
    "            # 'Sce_b',\n",
    "            #  'Sce_a',\n",
    "            *[f'Sce_d_seed{i}' for i in range(4,5)],\n",
    "    # *[f'Sce_b_seed{i}' for i in range(1,5)]\n",
    "             ]\n",
    "\n",
    "fitted_vals = {}\n",
    "\n",
    "\n",
    "fsize = figsizes.icml2024_half(ncols=1, nrows=len(scenarios), )\n",
    "fsize['figure.figsize'] = (fsize['figure.figsize'][0] * 0.8, fsize['figure.figsize'][1] * 0.75)\n",
    "with plt.rc_context(fsize):\n",
    "    fig, axs = plt.subplots(len(scenarios), 1, sharex=True, squeeze=False)\n",
    "\n",
    "    for ax, scenario in zip(axs.flatten(), scenarios):\n",
    "        for sampler in ['cpm']:\n",
    "\n",
    "            for i, (key, df) in enumerate(dict_with_dfs.items()):\n",
    "                if scenario == key.split('/')[1] and sampler in key and 'mcs' not in key:\n",
    "                    print(key)\n",
    "                    T, MSE, MSE_nofit = fit_T_and_calc_error(scenario, sampler, dict_with_dfs, true_parameters, key=key)\n",
    "                    print(T[-1])\n",
    "                    for col in true_parameters[scenario[:5]].columns:\n",
    "                        if 'J_0_0' in col:\n",
    "                            continue\n",
    "                        p = ax.plot((df[col] / T).values, label=col)\n",
    "                        color = p[-1].get_color()\n",
    "                        ax.hlines(true_parameters[scenario[:5]][col], xmin=0, xmax=100, colors=color, linestyle='--')\n",
    "                        ax.set_ylabel('Parmameter value')\n",
    "                        fitted_val = (df[col] / T).iloc[-1]\n",
    "                        if col not in fitted_vals:\n",
    "                            fitted_vals[col] = []\n",
    "                        fitted_vals[col].append(fitted_val)\n",
    "    # plt.title(f'{scenario} {sampler}')\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    labels = ['$\\lambda$', '$J(0,1)$', '$J(0,2)$', '$J(1,1)$', '$J(1,2)$', '$J(2,2)$']\n",
    "    fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, 1), ncol=3, frameon=False)\n",
    "    fig.supxlabel('Training iteration (x100)', fontsize=8)\n",
    "    plt.savefig(FIGURE_SAVEDIR + f'exp0_param_convergence_{scenario}.pdf', bbox_inches='tight')\n",
    "    plt.show()\n"
   ],
   "id": "3912ee13c16d1c8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fitted_vals = pd.DataFrame(fitted_vals)\n",
    "print(scenarios)"
   ],
   "id": "e04257e85ba7532b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "fitted_vals.mean()",
   "id": "ac278085813ca0b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "fitted_vals.std()",
   "id": "14a27c21af60be31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "true_parameters['Sce_f']",
   "id": "cd0741972968877e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8f8cb345a5aaf6c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
