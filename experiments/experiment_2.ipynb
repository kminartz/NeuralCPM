{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import jax\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import os\n",
    "import utils\n",
    "import optax\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from tueplots import bundles, figsizes\n",
    "# bundle = bundles.icml2024()\n",
    "plt.rcParams.update(bundles.icml2024(usetex=False, family='sans-serif'))\n",
    "from scipy.ndimage import rotate as rotation_fn\n",
    "from scipy.ndimage import label, binary_dilation, generate_binary_structure\n",
    "def shuffle(arr):\n",
    "    idx = np.random.choice(np.arange(arr.shape[0]), replace=False, size=arr.shape[0])\n",
    "    return arr[idx]\n",
    "# Hyperparameters\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY=1e-3\n",
    "STEPS = 676\n",
    "PRINT_EVERY = 25\n",
    "SEED = 12345678\n",
    "USE_RESIDUAL = True\n",
    "STRIDE_FIRST_LAYER=2\n",
    "\n",
    "FIGURE_SAVEDIR = 'Experiment_figures/'\n",
    "if not os.path.exists(FIGURE_SAVEDIR):\n",
    "    os.makedirs(FIGURE_SAVEDIR)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_data_batched_real(bs, data_dir, t=-1):\n",
    "\n",
    "    files = os.listdir(data_dir)\n",
    "    # select some random files to load:\n",
    "    selected_files = np.random.choice(files, size=bs, replace=False)  # list of .npz files\n",
    "    data = []\n",
    "    for f in tqdm(selected_files):\n",
    "        # load the final state of each simulation. shape is (t, 2, grid_size, grid_size)\n",
    "        arr = utils.load_data_from_file(os.path.join(data_dir, f))\n",
    "        # randomly rotate all all channels with a random number of degrees using built-in function from library:\n",
    "        angle = np.random.uniform(0, 360)\n",
    "        rotated_arr = rotation_fn(arr, angle, axes=(2, 3), reshape=False, order=0)\n",
    "        arr = rotated_arr\n",
    "        if t is not None:\n",
    "            t_int = t\n",
    "            arr = arr[t_int]\n",
    "        data.append(\n",
    "            arr[None, ...]\n",
    "        )  # now shape (1, [t], 2, grid_size, grid_size)\n",
    "    return np.concatenate(data).astype(int)"
   ],
   "id": "79f8938d6bee433f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "path = '../data/Exp_2_toda_padded/'\n",
    "all_data = load_data_batched_real(len(os.listdir(path)),\n",
    "        path, t=-1)"
   ],
   "id": "8de0e7a13d92413f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_data[0].shape",
   "id": "86b67a6a5d2a5910",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "colors = [\n",
    "            np.array([[0.,0.,0.]]),# black\n",
    "            np.array([[0.,0.,0.25]]),# dark blue\n",
    "            np.array([[1.,0.,0.]]), #  red\n",
    "            np.array([[204.,255.,11.]]) / 255. #  light green\n",
    "        ]\n",
    "\n",
    "fig, axs = plt.subplots(3, 5)\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    plotted = utils.plot_cell_image(all_data[i], ax, colors=colors)\n",
    "    # ax.set_title(f\"Label: {all_labels[i]}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(FIGURE_SAVEDIR+'some_real_data_exp2.png')\n",
    "plt.show()"
   ],
   "id": "e33cc2d1ff0c1f69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_data[0][0].max()",
   "id": "d68ab9ad7aea86b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "paths = []\n",
    "for p in os.listdir('Exp2/neuralcpm_base/'):\n",
    "    if p.endswith('.eqx'):\n",
    "        files = os.listdir(os.path.join('Exp2/neuralcpm_base/', p))\n",
    "        for f in files:\n",
    "            if f.endswith('.npz'):\n",
    "                paths.append(os.path.join('Exp2/neuralcpm_base/', p, f))\n",
    "\n",
    "\n",
    "datas = {}\n",
    "samples = {}\n",
    "energies = {}\n",
    "for path in paths:\n",
    "    data = np.load(path)\n",
    "    datas[path] = data\n",
    "    samples[path] = data['all_samples']\n",
    "    energies[path] = data['all_energies']\n",
    "    print(path, samples[path].shape)"
   ],
   "id": "5d68cd93b2108513",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calc_moment(datapoint, moment=1, types=(1,2), num_cells=41, rotate_alignment_type=None):\n",
    "    # shape of datapoint: 2, h, w - -first channel cell id, second cell type\n",
    "    moments = jnp.zeros((len(types), 2))\n",
    "    coms_types = {}\n",
    "    for i, type in enumerate(types):\n",
    "        type_mask = (datapoint[1] == type)[None, ...]\n",
    "        data_type = jnp.where(type_mask, datapoint, 0)\n",
    "        coms = utils.get_cells_com(data_type, num_cells)[1:]  # note: this will give NaN for non-existing cells. format x, y\n",
    "        coms_types[type] = coms\n",
    "    if rotate_alignment_type in types:\n",
    "        # we find the coms of this type, and rotate all coms of all types with the principal components of this type\n",
    "        coms = coms_types[rotate_alignment_type]\n",
    "        coms = coms[~jnp.isnan(coms).any(axis=1)]\n",
    "        if len(coms) <= 1:\n",
    "            coms = coms_types[rotate_alignment_type].at[:].set(jnp.nan)\n",
    "        mean = jnp.nanmean(coms, axis=0)\n",
    "        coms = coms - mean\n",
    "        cov = jnp.cov(coms, rowvar=False)\n",
    "        eigvals, eigvecs = jnp.linalg.eigh(cov)\n",
    "        # sort eigenvectors by eigenvalues\n",
    "        idx = jnp.argsort(eigvals)[::-1]\n",
    "        eigvecs = eigvecs[:, idx]\n",
    "        coms_types = {k: jnp.dot(v - mean, eigvecs) for k, v in coms_types.items()}\n",
    "    # finally, calculate the moments in the possibly transformed coordinate system and return them:\n",
    "    for i, type in enumerate(types):\n",
    "        coms = coms_types[type]\n",
    "        if moment == 0:\n",
    "            moments = moments.at[i].set(jnp.sum(~jnp.isnan(coms), axis=0))\n",
    "        elif moment == 1:\n",
    "            moments = moments.at[i].set(jnp.nanmean(coms, axis=0))\n",
    "        else: # calculate the centralized moment:\n",
    "            mean = jnp.nanmean(coms, axis=0)\n",
    "            moments = moments.at[i].set(jnp.nanmean((coms - mean) ** moment, axis=0))\n",
    "    return moments  # shape types, coords\n"
   ],
   "id": "6c7f2a4ad4254bf0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print('zeroth moment training data:')\n",
    "# m0_real = jax.vmap(calc_moment, in_axes=(0, None))(all_data, 0).mean(0)"
   ],
   "id": "8ef6280046cb7895",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print('first moment training data:')\n",
    "# m1_real = jax.vmap(calc_moment, in_axes=(0, None))(all_data, 1).mean(0)"
   ],
   "id": "6d2a289a9a4df93d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('second moment training data:')\n",
    "m2s_real = []\n",
    "for d in tqdm(all_data):\n",
    "    # print(d.shape)\n",
    "    m2 = calc_moment(d, 2, rotate_alignment_type=2)\n",
    "    m2s_real.append(m2)\n",
    "# m2_real = jax.vmap(calc_moment, in_axes=(0, None, None, None, None))(all_data, 2,(1,2),41,1).mean(0)"
   ],
   "id": "cb3bd1141e9045d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "m2_real = jnp.nanmean(jnp.stack(m2s_real, axis=0), axis=0)",
   "id": "4b302d68933caee0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "52bf35d0daeca28e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "m2_samples = {}\n",
    "m2s_samples = {}\n",
    "if 'data_real' in samples:\n",
    "    samples.pop('data_real')\n",
    "for k, v in samples.items():\n",
    "    sample_final = v[:, -1]\n",
    "    print(k)\n",
    "    m2s_sample_this = []\n",
    "    for d in tqdm(sample_final):\n",
    "        # print(d.shape)\n",
    "        m2 = calc_moment(d, 2, rotate_alignment_type=2)\n",
    "        m2s_sample_this.append(m2)\n",
    "    m2_samples[k.split(\"/\")[-2] if '/' in k else k] = jnp.nanmean(jnp.stack(m2s_sample_this, axis=0), axis=0)\n",
    "    m2s_samples[k.split(\"/\")[-2] if '/' in k else k] = jnp.stack(m2s_sample_this, axis=0)"
   ],
   "id": "1a0d5eacd1098fc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "list(m2_samples.values())[0]",
   "id": "6747ecb184fd5180",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "m2s_real_arr = jnp.stack(m2s_real, axis=0)\n",
    "m2s_real_arr.shape"
   ],
   "id": "217a8b6d4800aadd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#rebuttal: test if mean alignment is identical to training data:\n",
    "from scipy.stats import ttest_ind, kstest, false_discovery_control\n",
    "\n",
    "# types = (0,1)\n",
    "# axes = (0,1)\n",
    "#\n",
    "# for k in m2_samples.keys():\n",
    "#     print(f'\\n {k} \\n')\n",
    "#     for type in types:\n",
    "#         for ax in axes:\n",
    "#             m2s_real_this = m2s_real_arr[:, type, ax]\n",
    "#             m2s_sample_this = m2s_samples[k][:, type, ax]\n",
    "#             # stat, p = ttest_ind(m2s_real_this, m2s_sample_this, equal_var=False, nan_policy='omit')\n",
    "#             stat, p = kstest(m2s_real_this, m2s_sample_this, nan_policy='omit')\n",
    "#             print(f'type {type}, axis {ax}: p-value: {p}')\n",
    "\n",
    "\n",
    "# calculate RMSE based on sub-sampled data:\n",
    "\n",
    "subsamp_size=10\n",
    "all_rmses = {}\n",
    "for k in m2_samples.keys():\n",
    "    rmses = []\n",
    "    m2s_samples_key = m2s_samples[k]\n",
    "    for i_start in range(0, m2s_samples_key.shape[0], subsamp_size):\n",
    "        m2s_sample_this = m2s_samples_key[i_start:i_start+subsamp_size]\n",
    "        m2_mean_this = jnp.nanmean(m2s_sample_this, axis=0)\n",
    "        rmse = jnp.sqrt(jnp.mean((m2_mean_this - m2_real) ** 2))\n",
    "        rmses.append(rmse)\n",
    "    all_rmses[k] = np.array(rmses)\n",
    "\n",
    "\n",
    "from scipy.stats import ttest_ind, shapiro\n",
    "\n",
    "base_key = 'experiment_2_nch3_2950.eqx'\n",
    "keys = []\n",
    "p_values = []\n",
    "base = all_rmses.pop(base_key)\n",
    "\n",
    "\n",
    "for k, v in all_rmses.items():\n",
    "    # print(jnp.mean(v), jnp.std(v))\n",
    "    stat, p = ttest_ind(base, v, equal_var=False, nan_policy='omit')\n",
    "    # bonferroni correction:\n",
    "    p = p * len(all_rmses)\n",
    "    p_values.append(p)\n",
    "    keys.append(k)\n",
    "    print(k, stat, p)\n",
    "\n",
    "print('\\n\\n')\n",
    "# test normality:\n",
    "stat, p = shapiro(base)\n",
    "print('normality test:', stat, p)\n",
    "for k, v in all_rmses.items():\n",
    "    # test normality:\n",
    "    stat, p = shapiro(v)\n",
    "    print(k, 'normality test:', stat, p)\n",
    "\n"
   ],
   "id": "4fc59265e4e25698",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n"
   ],
   "id": "1db7b728b7c4b871",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_rmses.keys()",
   "id": "78e19cbae3112a85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('RMSE')\n",
    "for k, v in m2_samples.items():\n",
    "    rmse = jnp.sqrt(jnp.mean((v - m2_real) ** 2))\n",
    "    print(k, rmse)\n",
    "\n",
    "\n",
    "print('normalized RMSE')\n",
    "for k, v in m2_samples.items():\n",
    "    m2_real_norm = m2_real / jnp.sum(m2_real, axis=1, keepdims=True)\n",
    "    v_norm = v / jnp.sum(v, axis=1, keepdims=True)\n",
    "    rmse = jnp.sqrt(jnp.mean((v_norm - m2_real_norm) ** 2))\n",
    "    print(k, rmse)"
   ],
   "id": "f2f8bef3e59fae07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ad51c3ac208f5fa4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# a single plot with one qualitative example for each model:\n",
    "\n",
    "# qualitative plots for true and generated samples:\n",
    "stepsize = 20\n",
    "max_steps = 1000\n",
    "\n",
    "if 'real_data' in samples:\n",
    "    samples.pop('real_data')\n",
    "\n",
    "\n",
    "\n",
    "names_of_models = ['experiment_2_cellsort_9950.eqx', 'experiment_2_ext_pot_9950.eqx', 'experiment_2_conv_ham_500.eqx',\n",
    "                   'experiment_2_shallow_nh_400.eqx', 'experiment_2_nh_3200.eqx', 'experiment_2_nch3_2950.eqx']\n",
    "names_to_plot = ['Cellsort\\nHamiltonian', 'Cellsort\\nHamiltonian\\n+External\\nPotential', 'CNN', '1-layer\\nNeural\\nHamiltonian\\n+CNN',\n",
    "                 'Neural\\nHamiltonian', 'Neural\\nHamiltonian\\n+closure']\n",
    "\n",
    "if not os.path.exists(os.path.join(FIGURE_SAVEDIR, 'add_qual_exp2')):\n",
    "    os.makedirs(os.path.join(FIGURE_SAVEDIR, 'add_qual_exp2'))\n",
    "\n",
    "for plot_id in range(4):\n",
    "    keys = list(samples.keys())\n",
    "    data_to_plot = []\n",
    "\n",
    "    for name in names_of_models:\n",
    "        k = list(filter(lambda x: name in x, keys))[0]\n",
    "        print(name, k)\n",
    "        v = samples[k]\n",
    "        sample = v\n",
    "        data_this = shuffle(sample)[0:1] #[shuffle(some_data_incl_time)[0:1]]\n",
    "        data_to_plot.append(data_this[:, :100])\n",
    "\n",
    "    data_to_plot = np.concatenate(data_to_plot, axis=0)\n",
    "    ts_to_plot = [i * stepsize for i in range(min(data_to_plot.shape[1] // stepsize, max_steps))]\n",
    "    mcs_per_t = 134 * 50 / (data_to_plot.shape[-1] * data_to_plot.shape[-2])\n",
    "\n",
    "    time_labels = [i * float(np.round(750 / 4/60, 1)) for i in range(5)]\n",
    "    fig, axs = plt.subplots(len(data_to_plot), len(ts_to_plot), figsize=(len(ts_to_plot)*1, len(data_to_plot)), squeeze=False, gridspec_kw={'wspace': 0.05, 'hspace': 0.05})\n",
    "\n",
    "\n",
    "    print(data_to_plot.shape)\n",
    "    print(axs.shape)\n",
    "    utils.plot_cell_trajectory_data(data_to_plot, len(data_to_plot), ts_to_plot, axs, colors=colors)\n",
    "\n",
    "\n",
    "    # Adjust axis labels and formatting\n",
    "    for i, ax_row in enumerate(axs):\n",
    "        for j, ax in enumerate(ax_row):\n",
    "            ax.axis(\"on\")  # Explicitly enable axes for adding labels\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            if j == 0:  # Add row labels to the left of the subplots\n",
    "                ax.set_ylabel(\n",
    "                    names_to_plot[i], fontsize=8, labelpad=20,\n",
    "                    rotation=90, va=\"center\", ha=\"center\"\n",
    "                )\n",
    "            if i == len(axs) - 1:  # Add x-axis labels below the bottom row\n",
    "                ax.set_xlabel(f\"{time_labels[j]}\", fontsize=8, labelpad=10)\n",
    "\n",
    "    # Adjust layout and show the plot\n",
    "    plt.tight_layout(rect=[0.05, 0.05, 0.05, 0.05])  # Leave space for labels\n",
    "\n",
    "    # Add a global x-axis label for time in seconds\n",
    "    fig.text(0.5, 0.04, 'Time (hours)', ha='center', va='center', fontsize=9)\n",
    "    plt.savefig(os.path.join(FIGURE_SAVEDIR, 'add_qual_exp2', f'traj_2_qual_{plot_id}.pdf'), dpi=400)\n",
    "    plt.show()\n",
    "\n",
    "print('\\n')"
   ],
   "id": "fd1c39eec8d0a305",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "axs.shape",
   "id": "532696d08361532d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ts_to_plot",
   "id": "11c3a0b885972d14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4ea7fcb399ad6f82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "87c488169c9abd7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "835121310c7f3c11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1fceabea5bf7a7a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f72946509849f39f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f3e6382b0e562881",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculate the stable states:\n",
    "\n",
    "num_cells = len(np.unique(all_data[:,0]))\n",
    "volumes = jax.vmap(utils.calculate_all_cell_volumes, in_axes=(0, None))(all_data, num_cells)[:, 1:] # ignore medium\n",
    "\n",
    "vol_low, vol_high = np.min(volumes), np.max(volumes)"
   ],
   "id": "d146e6253f424a49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "vol_low, vol_high",
   "id": "30ca2fc413e9524",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "eb8c7a410fe51aa4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8b87930b37a048b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "list(samples.values())[0].shape",
   "id": "395ed6280f84d55c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "samples['data_real'] = all_data[:, None]",
   "id": "8789074c7afa4a28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stable_dict = {}\n",
    "frag_dict = {}\n",
    "vol_dict = {}\n",
    "\n",
    "neighborhood_order=4\n",
    "from scipy.ndimage import label\n",
    "\n",
    "\n",
    "\n",
    "def calc_frag_batched(samples, num_cells, neighborhood_order): # this is not transformable under jax unfortunately\n",
    "    num_fragmented = np.zeros(samples.shape[0])\n",
    "    for i, sample in enumerate(samples):\n",
    "        num_fragmented[i] = utils.count_num_fragmented(sample, num_cells, neighborhood_order)\n",
    "    return num_fragmented\n",
    "\n",
    "calc_vol_batched = eqx.filter_jit(jax.vmap(\n",
    "            utils.calculate_all_cell_volumes, in_axes=(0, None)\n",
    "        ))\n",
    "for k, v in samples.items():\n",
    "    print(k)\n",
    "    sample = v\n",
    "    stable_times = []\n",
    "    frag_times = []\n",
    "    vol_times = []\n",
    "    for t in tqdm(range(0, sample.shape[1], 5)):\n",
    "        # stable = calc_stable_batched(sample[:, t], num_cells, vol_low, vol_high, 0, 0, 2)\n",
    "        frag = calc_frag_batched(np.array(sample[:, t]), num_cells, neighborhood_order)\n",
    "        vol = calc_vol_batched(sample[:, t], num_cells)[:, 1:]\n",
    "        # stable_times.append(stable[:, None, ...])\n",
    "        frag_times.append(frag[:, None, ...])\n",
    "        vol_times.append(vol[:, None, ...])\n",
    "    # stable_dict[k] = np.concatenate(stable_times, axis=1)\n",
    "    frag_dict[k] = np.concatenate(frag_times, axis=1)\n",
    "    vol_dict[k] = np.concatenate(vol_times, axis=1)"
   ],
   "id": "d41ce336876925a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "min_vol = vol_low - 15\n",
    "max_vol = vol_high + 15\n",
    "max_num_vol_violate = 0\n",
    "max_num_fragmented = 3\n",
    "\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "\n",
    "for k, v in frag_dict.items():\n",
    "    num_frag = v\n",
    "    vol = vol_dict[k]\n",
    "    vol_good = jnp.logical_or((vol < min_vol), (vol > max_vol)).sum(-1) <= max_num_vol_violate\n",
    "    frag_good = num_frag <= max_num_fragmented\n",
    "    stable = jnp.logical_and(frag_good, vol_good)\n",
    "    # stable = np.cumprod(stable, axis=1)\n",
    "    ax[0].plot(stable.mean(0), label=k)\n",
    "    # put legend above plot\n",
    "    ax[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), shadow=True, ncol=2)\n",
    "    ax[1].plot(vol_good.mean(0))\n",
    "    ax[2].plot(frag_good.mean(0))\n",
    "    name = k.split('/')[-2] if '/' in k else k\n",
    "    print(name, 'vol: ', vol_good.mean(), 'frag: ',frag_good.mean(), 'stable: ',stable.mean())\n",
    "# plt.legend()\n",
    "plt.show()"
   ],
   "id": "259baa7301c60cdf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load the data provided by Toda, preprocessed by Lutz:\n",
    "from PIL import Image\n",
    "data_toda_dir = 'toda_experiment_data/Toda2018_Fig.S6B_5samples_2channels_frames_equilib'\n",
    "\n",
    "# first get the prefix to match red and green channel:\n",
    "prefixes = set(map(lambda x: \"_\".join(x.split('_')[:-1]), os.listdir(data_toda_dir)))\n",
    "# load the images\n",
    "imgs = []\n",
    "for p in prefixes:\n",
    "    print(p)\n",
    "    red = Image.open(os.path.join(data_toda_dir, p+'_red.png'))\n",
    "    green = Image.open(os.path.join(data_toda_dir, p+'_green.png'))\n",
    "    red = np.array(red)\n",
    "    green = np.array(green)\n",
    "    blue = np.zeros_like(green)\n",
    "    im = np.stack([red, green, blue], axis=-1)\n",
    "    imgs.append(im)\n",
    "\n",
    "\n"
   ],
   "id": "3f2961473f9bb9a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def align_img_green_ch(im):\n",
    "    # find the pixels that are occupied by green\n",
    "    # then rotate the entire image using principle components of green\n",
    "\n",
    "    green = im[...,1]\n",
    "    pixels_green = np.stack(np.nonzero(green), axis=-1)  # pixels, 2 pixel coords\n",
    "    mean = np.mean(pixels_green, axis=0)\n",
    "    pixels_green = pixels_green - mean\n",
    "    cov = np.cov(pixels_green, rowvar=False)\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "    # sort eigenvectors by eigenvalues\n",
    "    idx = np.argsort(eigvals)[::-1]\n",
    "    eigvecs = eigvecs[:, idx]\n",
    "    # find the rotation corresponding to the eigenvectors -- align green horizontally:\n",
    "    angle = np.arctan2(eigvecs[0, 0], eigvecs[1, 0]) * 180 / np.pi\n",
    "    # rotate the image:\n",
    "    im = rotation_fn(im, angle, reshape=False, order=0)\n",
    "    return im\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_moment_image(im, moment=1):\n",
    "    im = align_img_green_ch(im)\n",
    "    moments = np.zeros((im.shape[-1], 2))  # shape: [num channels/cell types, 2(x,y)]\n",
    "    h_range = np.arange(im.shape[0]) / im.shape[0]\n",
    "    w_range = np.arange(im.shape[1]) / im.shape[1]\n",
    "    for c in range(im.shape[-1]):\n",
    "        ch_this = im[..., c]\n",
    "        E_h = (ch_this * h_range[:, None]).sum() / np.sum(ch_this)\n",
    "        E_w = (ch_this * w_range[None, :]).sum() / np.sum(ch_this)\n",
    "        if moment > 1:\n",
    "            m_h = (ch_this * (h_range[:, None] - E_h)**moment).sum() / np.sum(ch_this)\n",
    "            m_w = (ch_this * (w_range[None, :] - E_w)**moment).sum() / np.sum(ch_this)\n",
    "        else:\n",
    "            m_h, m_w = E_h, E_w\n",
    "        moments[c] = m_w, m_h  # x, y moments\n",
    "    return moments\n"
   ],
   "id": "9ff030ca76fbbd3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "thresh=165\n",
    "for i in range(3):\n",
    "    fig, axs = plt.subplots(1,2)\n",
    "    im = imgs[i].copy()\n",
    "    im = im * (im>thresh)\n",
    "    axs[0].imshow(im)\n",
    "    axs[1].imshow(align_img_green_ch(im))\n",
    "    plt.show()\n",
    "    # m2 = calc_moment_image(im, moment=2)\n",
    "    # m2_norm = m2 / np.sum(m2, axis=1, keepdims=True)\n",
    "    # print(m2, '\\n', m2_norm)"
   ],
   "id": "fff06b957fce94e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot a synthetic and real-world example side to side:\n",
    "colors = [\n",
    "            np.array([[0.,0.,0.]]),# black\n",
    "            np.array([[0.,0.,0.25]]),# dark blue\n",
    "            np.array([[1.,0.,0.]]), #  red\n",
    "            np.array([[204.,255.,11.]]) / 255. #  light green\n",
    "        ]\n",
    "fig, axs = plt.subplots(1, 4, figsize=(4,1.1),  gridspec_kw={'wspace': 0.05, 'hspace': 0.05})\n",
    "im = imgs[1].copy()\n",
    "\n",
    "\n",
    "axs[0].imshow(imgs[1].copy())\n",
    "axs[0].set_xticks([])\n",
    "axs[0].set_yticks([])\n",
    "axs[0].set_ylabel(\n",
    "    '\\nBipolar sorting', fontsize=7.8, labelpad=10,\n",
    "    rotation=90, va=\"center\", ha=\"center\"\n",
    ")\n",
    "\n",
    "axs[1].imshow(imgs[3].copy())\n",
    "axs[1].axis('off')\n",
    "\n",
    "im_synth = all_data[4].copy()\n",
    "utils.plot_cell_image(im_synth, axs[2], colors=colors)\n",
    "axs[2].axis('off')\n",
    "\n",
    "im_synth = all_data[18].copy()\n",
    "utils.plot_cell_image(im_synth, axs[3], colors=colors)\n",
    "axs[3].axis('off')\n",
    "\n",
    "\n",
    "# Add group labels for \"Type A\" and \"Type B\"\n",
    "fig.text(0.325, 0.05, 'Lab observations', fontsize=8, ha='center', va='top')\n",
    "fig.text(0.72, 0.05, 'Synthetic training data', fontsize=8, ha='center', va='top')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURE_SAVEDIR+'exp_2_real_and_synth_example.png', dpi=400, transparent=True)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "id": "d54796cdc4e7853e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "calc_moment_image(imgs[-1], moment=2)",
   "id": "72729300f5cb359c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "moments = []\n",
    "moments_norm = []\n",
    "thresh=165\n",
    "for i, im in enumerate(imgs):\n",
    "    im_thresh = im * (im > thresh)\n",
    "    m2 = calc_moment_image(im_thresh, moment=2)\n",
    "    m2_norm = m2 / np.sum(m2, axis=1, keepdims=True)\n",
    "    moments.append(m2)\n",
    "    moments_norm.append(m2_norm)"
   ],
   "id": "898f0d27c0843de7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.mean(np.stack(moments_norm, axis=0), axis=0)",
   "id": "a7fb1ebe9a1c3464",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.std(np.stack(moments_norm, axis=0), axis=0)",
   "id": "39f8dd6b9875ef1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculate moments for our training data:\n",
    "moments_synth = []\n",
    "moments_synth_norm = []\n",
    "for d in tqdm(all_data):\n",
    "    # shape (2, 149, 149)\n",
    "    im = np.zeros((d.shape[1], d.shape[2], 3)).astype(int)\n",
    "    im[..., 0] = 255 * (d[1] == 1)\n",
    "    im[..., 1] = 255 * (d[1] == 2)\n",
    "    im[..., 2] = 0\n",
    "    assert 0 < thresh < 255\n",
    "    im_thresh = im*(im>thresh)\n",
    "    m2 = calc_moment_image(im_thresh, moment=2)\n",
    "    m2_norm = m2 / np.sum(m2, axis=1, keepdims=True)\n",
    "    moments_synth.append(m2)\n",
    "    moments_synth_norm.append(m2_norm)"
   ],
   "id": "4b192a94cfd8ca80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.mean(np.stack(moments_synth_norm, axis=0), axis=0)",
   "id": "a60b57b8d3cfbd30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.std(np.stack(moments_synth_norm, axis=0), axis=0)",
   "id": "d4918f27e896d220",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculate moments for our sampled data from nch3 model:\n",
    "moments_model = []\n",
    "moments_model_norm = []\n",
    "for d_all_t in tqdm(samples['Exp2/neuralcpm_base/experiment_2_nch3_2950.eqx/samples_PermuteTypeInitializer_134_100_50.npz']):\n",
    "    d = d_all_t[-1]\n",
    "    # shape (2, 149, 149)\n",
    "    im = np.zeros((d.shape[1], d.shape[2], 3)).astype(int)\n",
    "    im[..., 0] = 255 * (d[1] == 1)\n",
    "    im[..., 1] = 255 * (d[1] == 2)\n",
    "    im[..., 2] = 0\n",
    "    assert 0 < thresh < 255\n",
    "    im_thresh = im*(im>thresh)\n",
    "    m2 = calc_moment_image(im_thresh, moment=2)\n",
    "    m2_norm = m2 / np.sum(m2, axis=1, keepdims=True)\n",
    "    moments_model.append(m2)\n",
    "    moments_model_norm.append(m2_norm)"
   ],
   "id": "6bf4646c08c9d417",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.mean(np.stack(moments_model_norm, axis=0), axis=0)\n",
   "id": "525234637b6a60e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a5fb9d450366c0ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot the moments of toda, morpheus,a nd our model as mean+ error bar of 1 std, for both type 1 and type 2 along the principal component of type 1:\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "mean_toda = np.mean(np.stack(moments_norm, axis=0), axis=0)[:2, 0] # shape (2) for type 1 and 2\n",
    "std_toda = np.std(np.stack(moments_norm, axis=0), axis=0)[:2, 0]\n",
    "mean_synth = np.mean(np.stack(moments_synth_norm, axis=0), axis=0)[:2, 0]\n",
    "std_synth = np.std(np.stack(moments_synth_norm, axis=0), axis=0)[:2, 0]\n",
    "mean_model = np.mean(np.stack(moments_model_norm, axis=0), axis=0)[:2, 0]\n",
    "std_model = np.std(np.stack(moments_model_norm, axis=0), axis=0)[:2, 0]\n",
    "\n",
    "\n",
    "# Data preparation\n",
    "labels = ['Type 1', 'Type 2']\n",
    "x = np.arange(len(labels))  # [0, 1]\n",
    "width = 0.25  # Bar width\n",
    "\n",
    "# Means and standard deviations for each group\n",
    "means = [mean_toda, mean_synth, mean_model]\n",
    "stds = [std_toda, std_synth, std_model]\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "group_labels = ['Toda et al., 2018 (real data)', 'Synthetic configurations', 'NeuralCPM (simulated)']\n",
    "hatches = ['\\\\', '/', '|']  # More subtle hatching\n",
    "\n",
    "#Plotting:\n",
    "\n",
    "fsize = figsizes.icml2024_half(ncols=1, nrows=1)\n",
    "fsize['figure.figsize'] = (fsize['figure.figsize'][0] * 1, fsize['figure.figsize'][1] * 0.8)\n",
    "with plt.rc_context(fsize):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for i, (mean, std, color, label, hatch) in enumerate(zip(means, stds, colors, group_labels, hatches)):\n",
    "        ax.bar(\n",
    "            x + i * width - width,  # Shift bars for each group\n",
    "            mean,\n",
    "            yerr=std,  # Add error bars\n",
    "            width=width,\n",
    "            label=label,\n",
    "            color=color,\n",
    "            alpha=0.75,  # Slight transparency\n",
    "            capsize=4,  # Error bar caps\n",
    "            edgecolor='black',  # Add edge for contrast\n",
    "            linewidth=0.7,  # Thin border,\n",
    "            hatch=hatch\n",
    "        )\n",
    "\n",
    "    # Axes labels and title\n",
    "    ax.set_ylabel('Variance fraction\\nalong polar axis')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    # legend_handles = [Patch(facecolor=color, edgecolor='black', hatch=hatch, label=label) for color, hatch, label in zip(colors, hatches, group_labels)]\n",
    "    # ax.legend(handles=legend_handles, frameon=False)\n",
    "\n",
    "    ax.legend(frameon=False)\n",
    "    # ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURE_SAVEDIR+'moments_comparison_T_final.pdf', dpi=400)\n",
    "    plt.show()\n",
    "\n"
   ],
   "id": "56f9dc198b3136b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ba53918875c1b795",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "42ff9c58db2c22cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3cbde0ba5c736c19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# now calculate the moments' development over time in the movie (shared by Toda, preprocessed by Lutz),\n",
    "# our synthetic data, and our samples"
   ],
   "id": "2bce780d7cf810fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f51f64a3e37c5ffd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_toda_dir = 'toda_experiment_data/Toda2018_separate_channels_dynamics'\n",
    "\n",
    "frames = range(1, 51)\n",
    "# load the images\n",
    "imgs_movie = []\n",
    "for f in frames:\n",
    "    # print(f)\n",
    "    this_frame = []\n",
    "    for channel in ['red', 'yellow']:\n",
    "        im = Image.open(os.path.join(data_toda_dir, f'Toda2018_{channel}_channel_frame_{f:02d}.png'))\n",
    "        im = np.array(im)\n",
    "        this_frame.append(im)\n",
    "    this_frame = np.stack(this_frame, axis=-1)\n",
    "    blue = np.zeros_like(this_frame[...,:1])\n",
    "    im = np.concatenate([this_frame, blue], axis=-1)\n",
    "    imgs_movie.append(im)"
   ],
   "id": "19ecd532d2b5fbb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(imgs_movie)",
   "id": "e43593a9f056c35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "thresh=25 # 20\n",
    "for i in range(0, 50, 20):\n",
    "    fig, axs = plt.subplots(1,2)\n",
    "    im = imgs_movie[i].copy()\n",
    "    im = im * (im>thresh)\n",
    "    axs[0].imshow(im)\n",
    "    axs[0].set_ylabel(f'{i+1}')\n",
    "    axs[1].imshow(align_img_green_ch(im))\n",
    "    # axs[2].hist(im.flatten())\n",
    "    # axs[2].set_yscale('log')\n",
    "    plt.show()"
   ],
   "id": "48084aa4175420dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# a single plot with one qualitative example for each model:\n",
    "colors = [\n",
    "            np.array([[0.,0.,0.]]),# black\n",
    "            np.array([[0.,0.,0.25]]),# dark blue\n",
    "            np.array([[1.,0.,0.]]), #  red\n",
    "            np.array([[204.,255.,11.]]) / 255. / 1.15 #  light green\n",
    "        ]\n",
    "\n",
    "# qualitative plots for true and generated samples:\n",
    "stepsize = 20\n",
    "max_steps = 1000\n",
    "\n",
    "if 'real_data' in samples:\n",
    "    samples.pop('real_data')\n",
    "\n",
    "\n",
    "data_to_plot = []\n",
    "names_of_models = ['experiment_2_cellsort_9950.eqx', 'experiment_2_ext_pot_9950.eqx', 'experiment_2_conv_ham_500.eqx',\n",
    "                   'experiment_2_shallow_nh_400.eqx', 'experiment_2_nh_3200.eqx', 'experiment_2_nch3_2950.eqx']\n",
    "names_to_plot = ['Cellsort\\nHamiltonian', 'Cellsort\\nHamiltonian\\n+External\\nPotential', 'CNN', '1 NH layer\\n+CNN',\n",
    "                 'Neural\\nHamiltonian', 'Neural\\nHamiltonian\\n+closure']\n",
    "\n",
    "keys = list(samples.keys())\n",
    "\n",
    "\n",
    "for name in names_of_models:\n",
    "    k = list(filter(lambda x: name in x, keys))[0]\n",
    "    print(name, k)\n",
    "    v = samples[k]\n",
    "    sample = v\n",
    "    data_this = shuffle(sample)[0:1] #[shuffle(some_data_incl_time)[0:1]]\n",
    "    data_this = data_this[:, :100]\n",
    "    data_to_plot.append(data_this)\n",
    "\n",
    "data_to_plot = np.concatenate(data_to_plot, axis=0)\n",
    "ts_to_plot = [i * stepsize for i in range(min(data_to_plot.shape[1] // stepsize, max_steps))]\n",
    "time_labels = [i * float(np.round(750 / 4/60, 1)) for i in range(5)]\n",
    "\n",
    "fig, axs = plt.subplots(len(data_to_plot)+1, len(ts_to_plot), figsize=(len(ts_to_plot)*1, len(data_to_plot)+1), squeeze=False, gridspec_kw={'wspace': 0.05, 'hspace': 0.05})\n",
    "\n",
    "num_mcs_per_t = 134 * 50 / (data_to_plot.shape[-1] * data_to_plot.shape[-2])\n",
    "\n",
    "# plot toda et al movie:\n",
    "\n",
    "for i in range(0, 5):\n",
    "    im = imgs_movie[i*10].copy()\n",
    "    axs[0, i].imshow(im)\n",
    "    if i == 0:\n",
    "        axs[0, i].set_ylabel('Toda et al.,\\n2018\\n(real data)', fontsize=8, labelpad=20,\n",
    "                    rotation=90, va=\"center\", ha=\"center\")\n",
    "    axs[0, i].axis(\"on\")  # Explicitly enable axes for adding labels\n",
    "    axs[0, i].set_xticks([])\n",
    "    axs[0, i].set_yticks([])\n",
    "\n",
    "\n",
    "utils.plot_cell_trajectory_data(data_to_plot, len(data_to_plot), ts_to_plot, axs[1:], colors=colors)\n",
    "\n",
    "\n",
    "# Adjust axis labels and formatting\n",
    "for i, ax_row in enumerate(axs[1:]):\n",
    "    for j, ax in enumerate(ax_row):\n",
    "        ax.axis(\"on\")  # Explicitly enable axes for adding labels\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if j == 0:  # Add row labels to the left of the subplots\n",
    "            ax.set_ylabel(\n",
    "                names_to_plot[i], fontsize=8, labelpad=20,\n",
    "                rotation=90, va=\"center\", ha=\"center\"\n",
    "            )\n",
    "        if i == len(axs)-2:  # Add x-axis labels below the bottom row\n",
    "            ax.set_xlabel(f\"{time_labels[j]}\", fontsize=8, labelpad=10)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout(rect=[0.05, 0.05, 0.05, 0.05])  # Leave space for labels\n",
    "\n",
    "# Add a global x-axis label for time in seconds\n",
    "fig.text(0.5, 0.04, 'Time (hours)', ha='center', va='center', fontsize=9)\n",
    "plt.savefig(FIGURE_SAVEDIR+'traj_exp2-incl-toda.pdf', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "print('\\n')"
   ],
   "id": "eccc05d1fd6de7d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#REBUTTAL:\n",
    "\n",
    "\n",
    "# a single plot with one qualitative example for each model:\n",
    "colors = [\n",
    "            np.array([[0.,0.,0.]]),# black\n",
    "            np.array([[0.,0.,0.25]]),# dark blue\n",
    "            np.array([[1.,0.,0.]]), #  red\n",
    "            np.array([[204.,255.,11.]]) / 255. / 1.15 #  light green\n",
    "        ]\n",
    "\n",
    "# qualitative plots for true and generated samples:\n",
    "stepsize = 20\n",
    "max_steps = 1000\n",
    "\n",
    "if 'real_data' in samples:\n",
    "    samples.pop('real_data')\n",
    "\n",
    "\n",
    "data_to_plot = []\n",
    "names_of_models = ['experiment_2_closure_gnn_6100.eqx'] * 3 + ['experiment_2_nch_no_interactions_3700.eqx'] * 3\n",
    "names_to_plot = 3*['GNN\\n+ closure'] + 3*['NH + closure\\nno interactions']\n",
    "\n",
    "keys = list(samples.keys())\n",
    "\n",
    "\n",
    "for name in names_of_models:\n",
    "    k = list(filter(lambda x: name in x, keys))[0]\n",
    "    print(name, k)\n",
    "    v = samples[k]\n",
    "    sample = v\n",
    "    data_this = shuffle(sample)[0:1] #[shuffle(some_data_incl_time)[0:1]]\n",
    "    data_this = data_this[:, :100]\n",
    "    data_to_plot.append(data_this)\n",
    "\n",
    "data_to_plot = np.concatenate(data_to_plot, axis=0)\n",
    "ts_to_plot = [i * stepsize for i in range(min(data_to_plot.shape[1] // stepsize, max_steps))]\n",
    "time_labels = [i * float(np.round(750 / 4/60, 1)) for i in range(5)]\n",
    "\n",
    "fig, axs = plt.subplots(len(data_to_plot), len(ts_to_plot), figsize=(len(ts_to_plot)*1, len(data_to_plot)+1), squeeze=False, gridspec_kw={'wspace': 0.05, 'hspace': 0.05})\n",
    "\n",
    "num_mcs_per_t = 134 * 50 / (data_to_plot.shape[-1] * data_to_plot.shape[-2])\n",
    "\n",
    "\n",
    "\n",
    "utils.plot_cell_trajectory_data(data_to_plot, len(data_to_plot), ts_to_plot, axs, colors=colors)\n",
    "\n",
    "\n",
    "# Adjust axis labels and formatting\n",
    "for i, ax_row in enumerate(axs):\n",
    "    for j, ax in enumerate(ax_row):\n",
    "        ax.axis(\"on\")  # Explicitly enable axes for adding labels\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if j == 0:  # Add row labels to the left of the subplots\n",
    "            ax.set_ylabel(\n",
    "                names_to_plot[i], fontsize=8, labelpad=20,\n",
    "                rotation=90, va=\"center\", ha=\"center\"\n",
    "            )\n",
    "        if i == len(axs)-1:  # Add x-axis labels below the bottom row\n",
    "            ax.set_xlabel(f\"{time_labels[j]}\", fontsize=8, labelpad=10)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout(rect=[0.05, 0.05, 0.05, 0.05])  # Leave space for labels\n",
    "\n",
    "# Add a global x-axis label for time in seconds\n",
    "fig.text(0.5, 0.04, 'Time (hours)', ha='center', va='center', fontsize=9)\n",
    "plt.savefig(FIGURE_SAVEDIR+'traj_exp2_rebuttal.pdf', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "print('\\n')\n",
    "\n"
   ],
   "id": "4ae78133ffe8a7bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "moments_movie = []\n",
    "moments_movie_norm = []\n",
    "for i, im in enumerate(imgs_movie):\n",
    "    im_thresh = im * (im > thresh)\n",
    "    m2 = calc_moment_image(im_thresh, moment=2)\n",
    "    m2_norm = m2 / np.sum(m2, axis=1, keepdims=True)\n",
    "    moments_movie.append(m2)\n",
    "    moments_movie_norm.append(m2_norm)"
   ],
   "id": "9a9f7866829ca9b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# moments_movie_norm[0]",
   "id": "af434609870e391e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3b466104042220c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot the normalized moment in the x direction for both types\n",
    "to_plot_movie = []\n",
    "for m in moments_movie_norm:\n",
    "    to_plot_movie.append(m[:2, 0])\n",
    "to_plot_movie = np.stack(to_plot_movie, axis=0)"
   ],
   "id": "916ec2842aaf37b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(to_plot_movie)\n",
    "plt.show()"
   ],
   "id": "78f3c733d6967cb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d8b1f855fab9d565",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Now get the morpheus and sampled data and make a similar plot:\n",
    "\n",
    "path = '../data/Exp_2_toda_padded/'\n",
    "all_data_incl_time = load_data_batched_real(100, #len(os.listdir(path)),\n",
    "        path, t=None)\n"
   ],
   "id": "5af86e94f5e4690f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "moments_dynamic_morpheus_norm = []\n",
    "for d in tqdm(all_data_incl_time):\n",
    "    moments_this_traj = []\n",
    "    for d_t in d:\n",
    "        im = np.zeros((d_t.shape[1], d_t.shape[2], 3)).astype(int)\n",
    "        im[..., 0] = 255 * (d_t[1] == 1)\n",
    "        im[..., 1] = 255 * (d_t[1] == 2)\n",
    "        im[..., 2] = 0\n",
    "        assert 0 < thresh < 255\n",
    "        im_thresh = im*(im>thresh)\n",
    "        m2 = calc_moment_image(im_thresh, moment=2)\n",
    "        m2_norm = m2 / np.sum(m2, axis=1, keepdims=True)\n",
    "        moments_this_traj.append(m2_norm[:2, 0])\n",
    "    moments_dynamic_morpheus_norm.append(moments_this_traj)\n",
    "moments_dynamic_morpheus_norm = np.array(moments_dynamic_morpheus_norm)"
   ],
   "id": "9b834484227daa91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(moments_dynamic_morpheus_norm.mean(0))\n",
    "# plt.fill_between(range(moments_dynamic_morpheus_norm.shape[1]),\n",
    "#                     moments_dynamic_morpheus_norm.mean(0) - moments_dynamic_morpheus_norm.std(0),\n",
    "#                     moments_dynamic_morpheus_norm.mean(0) + moments_dynamic_morpheus_norm.std(0),\n",
    "#                     alpha=0.2)\n",
    "plt.show()"
   ],
   "id": "d224bc2381fbeefd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "moments_dynamic_samples_norm = []\n",
    "for d in tqdm(samples['Exp2/neuralcpm_base/experiment_2_nch3_2950.eqx/samples_PermuteTypeInitializer_134_100_50.npz']):\n",
    "    moments_this_traj = []\n",
    "    for d_t in d:\n",
    "        im = np.zeros((d_t.shape[1], d_t.shape[2], 3)).astype(int)\n",
    "        im[..., 0] = 255 * (d_t[1] == 1)\n",
    "        im[..., 1] = 255 * (d_t[1] == 2)\n",
    "        im[..., 2] = 0\n",
    "        assert 0 < thresh < 255\n",
    "        im_thresh = im*(im>thresh)\n",
    "        m2 = calc_moment_image(im_thresh, moment=2)\n",
    "        m2_norm = m2 / np.sum(m2, axis=1, keepdims=True)\n",
    "        moments_this_traj.append(m2_norm[:2, 0])\n",
    "    moments_dynamic_samples_norm.append(moments_this_traj)\n",
    "moments_dynamic_samples_norm = np.array(moments_dynamic_samples_norm)"
   ],
   "id": "ae9447c00aac830c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "moments_dynamic_samples_norm[:, -1].mean(0)",
   "id": "ebb76ff73ce984d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "fsize = figsizes.icml2024_half(ncols=1, nrows=1)\n",
    "fsize['figure.figsize'] = (fsize['figure.figsize'][0] * 1, fsize['figure.figsize'][1] * 0.8)\n",
    "with plt.rc_context(fsize):\n",
    "\n",
    "    colors = [\n",
    "                np.array([[0.,0.,0.]]),# black\n",
    "                np.array([[0.,0.,0.25]]),# dark blue\n",
    "                np.array([[1.,0.,0.]]), #  red\n",
    "                np.array([[204.,255.,11.]]) / 255. / 1.15 #  light green\n",
    "            ]\n",
    "\n",
    "    times = [i * 15 for i in range(to_plot_movie.shape[0])]\n",
    "    for i in range(2):\n",
    "        c = colors[i+2]\n",
    "        if i ==1:\n",
    "            c = c/1.15\n",
    "        m_this_type_sample = moments_dynamic_samples_norm[:, :-1:2, i]\n",
    "        m_this_type_movie = to_plot_movie[:, i]\n",
    "        plt.plot(times, m_this_type_sample.mean(0), color=c, label=f'type {str(i+1)} - NeuralCPM')\n",
    "        plt.fill_between(times,\n",
    "                        m_this_type_sample.mean(0) - m_this_type_sample.std(0),\n",
    "                        m_this_type_sample.mean(0) + m_this_type_sample.std(0),\n",
    "                        alpha=0.2, color=c)\n",
    "        plt.plot(times, m_this_type_movie, color=c, linestyle='None', marker='*', label=f'type {str(i+1)} - real data\\n(Toda et al., 2018)', markersize=6)\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.55), ncol=2, frameon=False)\n",
    "    plt.xlabel('Time (minutes)')\n",
    "    plt.ylabel('Variance fraction\\nalong polar axis')\n",
    "    # plt.ylim(0.1,0.8)\n",
    "    plt.savefig(FIGURE_SAVEDIR+'moment_dynamics-neuralcpm-toda.pdf')\n",
    "    plt.show()"
   ],
   "id": "82efe97945e4783e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# same but for cellsort simulator:\n",
    "\n",
    "moments_dynamic_samples_norm = []\n",
    "for d in tqdm(samples['Exp2/neuralcpm_base/experiment_2_cellsort_9950.eqx/samples_PermuteTypeInitializer_134_100_50.npz']):\n",
    "    moments_this_traj = []\n",
    "    for d_t in d:\n",
    "        im = np.zeros((d_t.shape[1], d_t.shape[2], 3)).astype(int)\n",
    "        im[..., 0] = 255 * (d_t[1] == 1)\n",
    "        im[..., 1] = 255 * (d_t[1] == 2)\n",
    "        im[..., 2] = 0\n",
    "        assert 0 < thresh < 255\n",
    "        im_thresh = im*(im>thresh)\n",
    "        m2 = calc_moment_image(im_thresh, moment=2)\n",
    "        m2_norm = m2 / np.sum(m2, axis=1, keepdims=True)\n",
    "        moments_this_traj.append(m2_norm[:2, 0])\n",
    "    moments_dynamic_samples_norm.append(moments_this_traj)\n",
    "moments_dynamic_samples_norm = np.array(moments_dynamic_samples_norm)\n",
    "\n",
    "fsize = figsizes.icml2024_half(ncols=1, nrows=1)\n",
    "fsize['figure.figsize'] = (fsize['figure.figsize'][0] * 1, fsize['figure.figsize'][1] * 1)\n",
    "with plt.rc_context(fsize):\n",
    "\n",
    "    colors = [\n",
    "                np.array([[0.,0.,0.]]),# black\n",
    "                np.array([[0.,0.,0.25]]),# dark blue\n",
    "                np.array([[1.,0.,0.]]), #  red\n",
    "                np.array([[204.,255.,11.]]) / 255. / 1.15 #  light green\n",
    "            ]\n",
    "\n",
    "    times = [i * 15 for i in range(to_plot_movie.shape[0])]\n",
    "    for i in range(2):\n",
    "        c = colors[i+2]\n",
    "        if i ==1:\n",
    "            c = c/1.15\n",
    "        m_this_type_sample = moments_dynamic_samples_norm[:, :-1:2, i]\n",
    "        m_this_type_movie = to_plot_movie[:, i]\n",
    "        plt.plot(times, m_this_type_sample.mean(0), color=c, label=f'type {str(i+1)} - Cellsort')\n",
    "        plt.fill_between(times,\n",
    "                        m_this_type_sample.mean(0) - m_this_type_sample.std(0),\n",
    "                        m_this_type_sample.mean(0) + m_this_type_sample.std(0),\n",
    "                        alpha=0.2, color=c)\n",
    "        plt.plot(times, m_this_type_movie, color=c, linestyle='None', marker='*', label=f'type {str(i+1)} - real data\\n(Toda et al., 2018)', markersize=6)\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.55), ncol=2, frameon=False)\n",
    "    plt.xlabel('Time (minutes)')\n",
    "    plt.ylabel('Variance fraction\\nalong polar axis')\n",
    "    plt.ylim(0.1,0.8)\n",
    "    plt.savefig(FIGURE_SAVEDIR+'moment_dynamics-cellsort-toda.pdf', dpi=400)\n",
    "    plt.show()\n",
    "\n"
   ],
   "id": "7bcd9dca74587d6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_to_plot[1:2].shape",
   "id": "b80042209efb0874",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# a single plot with one qualitative example for each model:\n",
    "colors = [\n",
    "            np.array([[0.,0.,0.]]),# black\n",
    "            np.array([[0.,0.,0.25]]),# dark blue\n",
    "            np.array([[1.,0.,0.]]), #  red\n",
    "            np.array([[204.,255.,11.]]) / 255. / 1.15 #  light green\n",
    "        ]\n",
    "\n",
    "# qualitative plots for true and generated samples:\n",
    "stepsize = 20\n",
    "max_steps = 1000\n",
    "\n",
    "if 'real_data' in samples:\n",
    "    samples.pop('real_data')\n",
    "\n",
    "\n",
    "data_to_plot = []\n",
    "names_of_models = ['experiment_2_cellsort_9950.eqx', 'experiment_2_nch3_2950.eqx']\n",
    "names_to_plot = ['CPM', 'NeuralCPM']\n",
    "\n",
    "keys = list(samples.keys())\n",
    "\n",
    "\n",
    "for name in names_of_models:\n",
    "    k = list(filter(lambda x: name in x, keys))[0]\n",
    "    print(name, k)\n",
    "    v = samples[k]\n",
    "    sample = v\n",
    "    data_this = shuffle(sample)[0:1] #[shuffle(some_data_incl_time)[0:1]]\n",
    "    data_this = data_this[:, :100]\n",
    "    data_to_plot.append(data_this)\n",
    "\n",
    "data_to_plot = np.concatenate(data_to_plot, axis=0)\n",
    "ts_to_plot = [i * stepsize for i in range(min(data_to_plot.shape[1] // stepsize, max_steps))]\n",
    "fig, axs = plt.subplots(len(data_to_plot)+1, len(ts_to_plot), figsize=(len(ts_to_plot)*1, len(data_to_plot)+1), squeeze=False, gridspec_kw={'wspace': 0.05, 'hspace': 0.05})\n",
    "\n",
    "\n",
    "# plot toda et al movie:\n",
    "\n",
    "for i in range(0, 5):\n",
    "    im = imgs_movie[i*10 + 5].copy()\n",
    "    axs[0, i].imshow(im)\n",
    "    if i == 0:\n",
    "        axs[0, i].set_ylabel('Laboratory\\nobservations', fontsize=8, labelpad=20,\n",
    "                    rotation=90, va=\"center\", ha=\"center\")\n",
    "    axs[0, i].axis(\"on\")  # Explicitly enable axes for adding labels\n",
    "    axs[0, i].set_xticks([])\n",
    "    axs[0, i].set_yticks([])\n",
    "\n",
    "\n",
    "utils.plot_cell_trajectory_data(data_to_plot, len(data_to_plot), ts_to_plot, axs[1:], colors=colors)\n",
    "\n",
    "\n",
    "# Adjust axis labels and formatting\n",
    "for i, ax_row in enumerate(axs[1:]):\n",
    "    for j, ax in enumerate(ax_row):\n",
    "        ax.axis(\"on\")  # Explicitly enable axes for adding labels\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if j == 0:  # Add row labels to the left of the subplots\n",
    "            ax.set_ylabel(\n",
    "                names_to_plot[i], fontsize=8, labelpad=20,\n",
    "                rotation=90, va=\"center\", ha=\"center\"\n",
    "            )\n",
    "\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout(rect=[0.05, 0.05, 0.05, 0.05])  # Leave space for labels\n",
    "\n",
    "# Add a global x-axis label for time in seconds\n",
    "# fig.text(0.5, 0.04, 'Time (MCS)', ha='center', va='center', fontsize=9)\n",
    "plt.savefig(FIGURE_SAVEDIR+'intro_figure.pdf', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "print('\\n')"
   ],
   "id": "5f1fe27c01201de6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bdf70c4979060cf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dbc605160b8e9075",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4e30b0145486364",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5ed4e8dc140398ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "82dd399b56682317",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2d88682964cd5db3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4e4549543f9a2c54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a463c769cb2c45e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b64dd9527d53f40b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7cc8b4a2e77984c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a5cf23ca091b2370",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c05490cbc39d46c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d9ef091909fe7975",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f17311950b742f41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "93e632d9fae3efe6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a404919389388915",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "74fb9f195b1acb18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b7d90611dd99823c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f56115829454c15b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "36e27f0a93d88f07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e1b24e8327b4b0a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "10a83e60924cb992",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3947d6d7c9e82c17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2e94af2183ad3f74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "614800f4a09b7388",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2b0d8e7e3525b022",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9c32ca0ddf02b6c1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
